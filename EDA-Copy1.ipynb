{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "514337de-7f6a-4c49-9f21-4af8c5360aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pandas_profiling\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pickle\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, LabelEncoder, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split, KFold, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, confusion_matrix\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b2dbadd-8428-4542-9129-7bea4c0884b3",
   "metadata": {},
   "source": [
    "## データ修正"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "4b512c47-bb30-42dd-bbea-277d9c31896e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#データ読み込み\n",
    "train = pd.read_csv(\"data/train_df.csv\")\n",
    "test = pd.read_csv(\"data/test_df.csv\")\n",
    "sample= pd.read_csv(\"data/submission.csv\",header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "dc9752b9-77c0-4740-b37d-63d8d217049a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pd.options.display.max_columns = 100\n",
    "random_state = 123\n",
    "# train = train[:10000]\n",
    "# test = test[:3000]\n",
    "# train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "7c246e1f-ba7c-426d-b5c3-d507d72c5cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#カテゴリと考えられる変数を変更\n",
    "train['id'] = train['id'].astype(object)\n",
    "train['personal_id_1'] = train['personal_id_1'].astype(object)\n",
    "train['personal_id_2'] = train['personal_id_2'].astype(object)                  \n",
    "train['facility_id'] = train['facility_id'].astype(object) \n",
    "train['icu_5'] = train['icu_5'].astype(object)\n",
    "train['icu_id'] = train['icu_id'].astype(object)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "fa29dc4d-c855-427f-b852-e2e62b3a89c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数値データ\n",
      "['age', 'bmi', 'situation_1', 'situation_2', 'height', 'weight', 'icu_4', 'icu_6', 'icu_7', 'icu_8', 'glasgow_coma_scale_1', 'glasgow_coma_scale_2', 'glasgow_coma_scale_3', 'glasgow_coma_scale_4', 'heart_rate', 'blood_oxy', 'arterial_pressure', 'respiratory_rate', 'temp', 'blood_pressure_1', 'blood_pressure_2', 'blood_pressure_3', 'blood_pressure_4', 'v1_heartrate_max', 'v2', 'v3', 'v4', 'v5', 'v6', 'v7', 'v8', 'v9', 'v10', 'v11', 'v12', 'v13', 'v14', 'v15', 'v16', 'w1', 'w2', 'w3', 'w4', 'w5', 'w6', 'w7', 'w8', 'w9', 'w10', 'w11', 'w12', 'w13', 'w14', 'w15', 'w16', 'w17', 'w18', 'x1', 'x2', 'x3', 'x4', 'x5', 'x6', 'aids', 'cirrhosis', 'diabetes', 'hepatic_issue', 'immunosuppression', 'leukemia', 'lymphoma', 'carcinoma']\n",
      "カテゴリ変数\n",
      "['id', 'personal_id_1', 'personal_id_2', 'facility_id', 'ethnicity', 'gender', 'icu_id', 'icu_1', 'icu_2', 'icu_3', 'icu_5', 'body_system_1', 'body_system_2']\n"
     ]
    }
   ],
   "source": [
    "# 数値データ\n",
    "x_train=train.drop('target_label',axis=1)\n",
    "col_num = x_train.columns[x_train.dtypes!='object'].values.tolist()\n",
    "print('数値データ')\n",
    "print(col_num)\n",
    "col_cat = x_train.columns[x_train.dtypes=='object'].values.tolist()\n",
    "print('カテゴリ変数')\n",
    "print(col_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "daa17a9d-9835-4668-8276-654ae1e7faf6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- unique_low --------------------\n",
      "['ethnicity', 'gender', 'icu_1', 'icu_2', 'icu_3', 'icu_5']\n",
      "-------------------- unique_high --------------------\n",
      "['id', 'personal_id_1', 'personal_id_2', 'facility_id', 'icu_id']\n",
      "-------------------- body_systems --------------------\n",
      "['body_system_1', 'body_system_2']\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "エンコーディングの方針\n",
    "nunique が比較的少ない変数はLabel Encoding\n",
    "nunique が多い変数はCount EncodingとTarget Encodingの併用\n",
    "\"\"\"\n",
    "\n",
    "low_cat_cols = [] # nunique が比較的少ない変数\n",
    "high_cat_cols = [] # nunique が多い変数\n",
    "\n",
    "for c in col_cat:\n",
    "    nunq = x_train[c].nunique()\n",
    "    if nunq>48:\n",
    "        high_cat_cols.append(c)\n",
    "    else:\n",
    "        low_cat_cols.append(c)\n",
    "        \n",
    "body_systems = ['body_system_1', 'body_system_2']\n",
    "for r in body_systems:\n",
    "    low_cat_cols.remove(r)\n",
    "        \n",
    "print('-'*20, 'unique_low', '-'*20)\n",
    "print(low_cat_cols)\n",
    "print('-'*20, 'unique_high', '-'*20)\n",
    "print(high_cat_cols)\n",
    "\n",
    "print('-'*20, 'body_systems', '-'*20)\n",
    "print(body_systems)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a0d7c301-b3a8-4cf0-bbe8-6d4b6d52b99d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ethnicity:\t['Caucasian' 'African American' 'Other/Unknown' 'Hispanic' nan 'Asian'\n",
      " 'Native American']\n",
      "gender:\t['M' 'F' nan]\n",
      "icu_1:\t['Floor' 'Accident & Emergency' 'Operating Room / Recovery'\n",
      " 'Other Hospital' 'Other ICU' nan]\n",
      "icu_2:\t['admit' 'readmit' 'transfer']\n",
      "icu_3:\t['MICU' 'CCU-CTICU' 'Med-Surg ICU' 'Neuro ICU' 'CSICU' 'SICU' 'CTICU'\n",
      " 'Cardiac ICU']\n",
      "icu_5:\t[302.0 nan 304.0 123.0 114.0 305.0 301.0 122.0 119.0 308.0 113.0 118.0\n",
      " 124.0 104.0 303.0 112.0 109.0 117.0 209.0 214.0 121.0 202.0 212.0 110.0\n",
      " 101.0 116.0 217.0 102.0 115.0 203.0 105.0 103.0 108.0 307.0 213.0 120.0\n",
      " 106.0 216.0 306.0 107.0 207.0 215.0 218.0 219.0 208.0]\n"
     ]
    }
   ],
   "source": [
    "#少ない要素は確認してみる\n",
    "for c in low_cat_cols:\n",
    "    print(f\"{c}:\\t{x_train[c].unique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b9e47ceb-33ed-4f0a-b06c-e6decfddf3ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ethnicity\n",
      "gender\n",
      "icu_1\n",
      "icu_2\n",
      "icu_3\n",
      "icu_5\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "#nunique が比較的少ない変数はLabel Encoding\n",
    "#body_system1,2は同様のカラムだと考えohe\n",
    "\n",
    "dict_low_cat = {}\n",
    "for col in low_cat_cols:\n",
    "    print(col)\n",
    "    value_fillna = 'unknown'\n",
    "    x_train[col] = x_train[col].fillna(value_fillna)\n",
    "    x_train[col] = x_train[col].astype(str)\n",
    "    # strに変換\n",
    "    le = LabelEncoder()\n",
    "    le.fit(x_train[col])\n",
    "    list_label = sorted(list(set(le.classes_) | set(['unknown'])))\n",
    "    # print(list_label)\n",
    "    map_label = {j:i for i,j in enumerate(list_label)}\n",
    "    train[col] = train[col].map(map_label)\n",
    "    \n",
    "    dict_low_cat[col] = {}\n",
    "    dict_low_cat[col]['fillna'] = value_fillna\n",
    "    dict_low_cat[col]['map_label'] = map_label\n",
    "    dict_low_cat[col]['num_label'] = len(list_label)\n",
    "\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f6b7c7bf-741e-4cd3-86d9-a12d056fb909",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "facility_id\n",
      "icu_id\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "# nunique が多い変数はCount EncodingとTarget Encodingの併用\n",
    "# クロスバリデーション内で行う\n",
    "\n",
    "# Count Encoding用\n",
    "ids = ['id', 'personal_id_1', 'personal_id_2']\n",
    "for i in ids:\n",
    "    high_cat_cols.remove(i)\n",
    "    \n",
    "dict_high_cat = {}\n",
    "for col in high_cat_cols :\n",
    "    print(col)\n",
    "    value_fillna = 'unknown'\n",
    "    x_train[col] = x_train[col].fillna(value_fillna)\n",
    "    x_train[col] = x_train[col].astype(str)\n",
    "    \n",
    "    map_count = x_train[col].value_counts().to_dict()\n",
    "    x_train['CE_' + col] = x_train[col].map(map_count)\n",
    "    \n",
    "    dict_high_cat[col] = {}\n",
    "    dict_high_cat[col]['fillna'] = value_fillna\n",
    "    dict_high_cat[col]['map_count'] = map_count\n",
    "    # dict_high_cat[col]['num_label'] = len(list_label)\n",
    "    \n",
    "    \n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2a19ded5-caf5-49e5-ad96-8f287ddcb9c6",
   "metadata": {},
   "source": [
    "# 数値データは標準化\n",
    "dict_num = {}\n",
    "for col in col_num:\n",
    "    print(col)\n",
    "    # 欠損値を0へ\n",
    "    value_fillna = 0 \n",
    "    x_train[col] = x_train[col].fillna(value_fillna)\n",
    "    # 正規化\n",
    "    value_min = x_train[col].min()\n",
    "    value_max = x_train[col].max()\n",
    "    value_mean = x_train[col].mean()\n",
    "    value_std = x_train[col].std()\n",
    "    train[col] = (x_train[col] - value_mean) / (value_std)\n",
    "    # X_tarin[col] = (X_train[col] - value_mean) / value_std\n",
    "    \n",
    "    dict_num[col] = {}\n",
    "    dict_num[col]['fillna'] = value_fillna\n",
    "    dict_num[col]['min'] = value_min\n",
    "    dict_num[col]['max'] = value_max\n",
    "    dict_num[col]['mean'] = value_max    \n",
    "    dict_num[col]['std'] = value_max    \n",
    "    \n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "0ca4da6d-792c-41f7-a397-68d69834b5e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_data(input_x):\n",
    "    output_x = input_x.copy()\n",
    "    \n",
    "#     for col in col_num:\n",
    "#         value_fillna = dict_num[col]['fillna']\n",
    "#         output_x[col] = output_x[col].fillna(value_fillna)\n",
    "        \n",
    "#         value_mean = dict_num[col]['mean']\n",
    "#         value_std = dict_num[col]['std']\n",
    "#         output_x[col]  = (output_x[col] - value_mean ) / (value_std)\n",
    "        \n",
    "    for col in low_cat_cols:\n",
    "        value_fillna = dict_low_cat[col]['fillna']\n",
    "        output_x[col] = output_x[col].fillna(value_fillna)\n",
    "        \n",
    "        output_x[col] = output_x[col].astype(str)\n",
    "        \n",
    "        map_label = dict_low_cat[col]['map_label']#辞書からlabelencordの辞書を取り出す\n",
    "        output_x[col] = output_x[col].map(map_label)\n",
    "        \n",
    "        #対応するものがない場合はunkoumn\n",
    "        output_x[col] = output_x[col].fillna(map_label['unknown'])\n",
    "        \n",
    "    for col in high_cat_cols:\n",
    "        value_fillna = dict_high_cat[col]['fillna']\n",
    "        output_x[col] = output_x[col].fillna(value_fillna)\n",
    "        \n",
    "        output_x[col] = output_x[col].astype(str)\n",
    "        \n",
    "        map_count = dict_high_cat[col]['map_count']#辞書からcountencodeの辞書を取り出す\n",
    "        output_x['CE_' + col] = output_x[col].map(map_count)\n",
    "        \n",
    "        \n",
    "    return output_x\n",
    "\n",
    "x_test = transform_data(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "fce8a177-8919-4fe5-b0ef-d372313dfb5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64199, 2) (64199, 86)\n",
      "['Cardiovascular' 'unknown' 'Gastrointestinal' 'Metabolic' 'Genitourinary'\n",
      " 'Neurological' 'Trauma' 'Sepsis' 'Respiratory' 'Musculoskeletal/Skin'\n",
      " 'Gynecological' 'Hematological']\n",
      "['unknown' 'Renal/Genitourinary' 'Neurologic' 'Undefined Diagnoses'\n",
      " 'Cardiovascular' 'Haematologic']\n"
     ]
    }
   ],
   "source": [
    "#body_sytemsとhigh_cat_cols（target_encord)以外修正後\n",
    "#データを統合しbody_sytemsをone_hotencoding\n",
    "\n",
    "# OHEのため全データ合算\n",
    "concat_df = pd.concat([x_train, x_test], sort=False, ignore_index = True)\n",
    "\n",
    "\n",
    "#病名のみのdf\n",
    "train_body=concat_df[['body_system_1','body_system_2']]\n",
    "#被っているものはbody_system_2をNanに\n",
    "train_body['body_system_2'] = train_body['body_system_2'].where(\n",
    "    train_body['body_system_1'] != train_body['body_system_2'])\n",
    "#Nanはunknoun\n",
    "train_body.fillna('unknown', inplace=True)\n",
    "\n",
    "train_body['body_system_2'] = train_body['body_system_2'].replace('Undefined diagnoses', 'Undefined Diagnoses')\n",
    "print(train_body.shape, concat_df.shape)\n",
    "\n",
    "print(train_body['body_system_1'].unique())\n",
    "print(train_body['body_system_2'].unique())\n",
    "# ohe実行\n",
    "ohe_body = pd.get_dummies(train_body.stack(), dummy_na=False, prefix='ohe').groupby(level=0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "412b88b8-1b44-47ea-ba27-4e64636d050c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "学習用データ: (51359, 99),   学習ラベル：(51359, 1),  テストデータ：(12840, 99)\n",
      "taget_encord用学習データ：(51359, 3),  target_encord用テストデータ：(12840, 2)\n",
      "陽性ラベルの割合: 8.629451508012227％\n"
     ]
    }
   ],
   "source": [
    "ohe_concat_df = pd.concat([concat_df, ohe_body], axis=1)#元の全体のDFに病歴のOHEをつなげる\n",
    "ohe_concat_df = ohe_concat_df.drop(['body_system_1','body_system_2','ohe_unknown'], axis=1)\n",
    "# 学習とテストに分解\n",
    "n_train = ohe_concat_df[:len(x_train)]\n",
    "n_train = pd.concat([n_train, train['target_label']], axis=1)\n",
    "y_train = train[['target_label']]\n",
    "\n",
    "n_test = ohe_concat_df[len(x_train):].reset_index(drop=True)\n",
    "\n",
    "# Target Encoding用のラベル付きのDataFrameを用意\n",
    "te_base_train = n_train[['facility_id', 'icu_id', 'target_label']].copy()\n",
    "te_base_test = n_test[['facility_id', 'icu_id']].copy()\n",
    "\n",
    "n_train.drop('target_label', axis=1, inplace=True)\n",
    "\n",
    "\n",
    "print('学習用データ: {},   学習ラベル：{},  テストデータ：{}'.format(\n",
    "    n_train.shape, y_train.shape, n_test.shape))\n",
    "print('taget_encord用学習データ：{},  target_encord用テストデータ：{}'.format(\n",
    "      te_base_train.shape, te_base_test.shape))\n",
    "\n",
    "print('陽性ラベルの割合: {}％'.format(\n",
    "    y_train.value_counts()[1] * 100 / len(n_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b5f798-d201-4266-9655-266991c3782c",
   "metadata": {},
   "source": [
    "def tranform_data_TE(cat_cols, input_x, train_label):#catslist, testdata(df), labels(series) =>df\n",
    "    output_x = input_x.copy()\n",
    "    \n",
    "    for c in cat_cols :\n",
    "        data_tmp = pd.DataFrame({c: output_x[c], 'target': train_label})\n",
    "        target_mean = data_tmp.groupby(c)['target'].mean()\n",
    "        output_x.loc[:, c] = output_x[c].map(target_mean)\n",
    "        \n",
    "    return  output_x\n",
    "\n",
    "\n",
    "cat_cols = ['facility_id', 'icu_id']\n",
    "n_test = tranform_data_TE(cat_cols, n_test, y_train['target_label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "c3bacccb-fcf7-4bcc-97c5-23b62f5938d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>personal_id_1</th>\n",
       "      <th>personal_id_2</th>\n",
       "      <th>facility_id</th>\n",
       "      <th>age</th>\n",
       "      <th>bmi</th>\n",
       "      <th>situation_1</th>\n",
       "      <th>situation_2</th>\n",
       "      <th>ethnicity</th>\n",
       "      <th>gender</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>icu_id</th>\n",
       "      <th>icu_1</th>\n",
       "      <th>icu_2</th>\n",
       "      <th>icu_3</th>\n",
       "      <th>icu_4</th>\n",
       "      <th>icu_5</th>\n",
       "      <th>icu_6</th>\n",
       "      <th>icu_7</th>\n",
       "      <th>icu_8</th>\n",
       "      <th>glasgow_coma_scale_1</th>\n",
       "      <th>glasgow_coma_scale_2</th>\n",
       "      <th>glasgow_coma_scale_3</th>\n",
       "      <th>glasgow_coma_scale_4</th>\n",
       "      <th>heart_rate</th>\n",
       "      <th>blood_oxy</th>\n",
       "      <th>arterial_pressure</th>\n",
       "      <th>respiratory_rate</th>\n",
       "      <th>temp</th>\n",
       "      <th>blood_pressure_1</th>\n",
       "      <th>blood_pressure_2</th>\n",
       "      <th>blood_pressure_3</th>\n",
       "      <th>blood_pressure_4</th>\n",
       "      <th>v1_heartrate_max</th>\n",
       "      <th>v2</th>\n",
       "      <th>v3</th>\n",
       "      <th>v4</th>\n",
       "      <th>v5</th>\n",
       "      <th>v6</th>\n",
       "      <th>v7</th>\n",
       "      <th>v8</th>\n",
       "      <th>v9</th>\n",
       "      <th>v10</th>\n",
       "      <th>v11</th>\n",
       "      <th>v12</th>\n",
       "      <th>v13</th>\n",
       "      <th>v14</th>\n",
       "      <th>v15</th>\n",
       "      <th>v16</th>\n",
       "      <th>w1</th>\n",
       "      <th>w2</th>\n",
       "      <th>w3</th>\n",
       "      <th>w4</th>\n",
       "      <th>w5</th>\n",
       "      <th>w6</th>\n",
       "      <th>w7</th>\n",
       "      <th>w8</th>\n",
       "      <th>w9</th>\n",
       "      <th>w10</th>\n",
       "      <th>w11</th>\n",
       "      <th>w12</th>\n",
       "      <th>w13</th>\n",
       "      <th>w14</th>\n",
       "      <th>w15</th>\n",
       "      <th>w16</th>\n",
       "      <th>w17</th>\n",
       "      <th>w18</th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "      <th>x6</th>\n",
       "      <th>aids</th>\n",
       "      <th>cirrhosis</th>\n",
       "      <th>diabetes</th>\n",
       "      <th>hepatic_issue</th>\n",
       "      <th>immunosuppression</th>\n",
       "      <th>leukemia</th>\n",
       "      <th>lymphoma</th>\n",
       "      <th>carcinoma</th>\n",
       "      <th>CE_facility_id</th>\n",
       "      <th>CE_icu_id</th>\n",
       "      <th>ohe_Cardiovascular</th>\n",
       "      <th>ohe_Gastrointestinal</th>\n",
       "      <th>ohe_Genitourinary</th>\n",
       "      <th>ohe_Gynecological</th>\n",
       "      <th>ohe_Haematologic</th>\n",
       "      <th>ohe_Hematological</th>\n",
       "      <th>ohe_Metabolic</th>\n",
       "      <th>ohe_Musculoskeletal/Skin</th>\n",
       "      <th>ohe_Neurologic</th>\n",
       "      <th>ohe_Neurological</th>\n",
       "      <th>ohe_Renal/Genitourinary</th>\n",
       "      <th>ohe_Respiratory</th>\n",
       "      <th>ohe_Sepsis</th>\n",
       "      <th>ohe_Trauma</th>\n",
       "      <th>ohe_Undefined Diagnoses</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>51359</td>\n",
       "      <td>12058</td>\n",
       "      <td>66446</td>\n",
       "      <td>83</td>\n",
       "      <td>37.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>182.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>95</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.902778</td>\n",
       "      <td>11</td>\n",
       "      <td>501.02</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>37.00</td>\n",
       "      <td>74.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>37.30</td>\n",
       "      <td>36.90</td>\n",
       "      <td>65.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>451</td>\n",
       "      <td>451.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>51360</td>\n",
       "      <td>92348</td>\n",
       "      <td>32311</td>\n",
       "      <td>185</td>\n",
       "      <td>60.0</td>\n",
       "      <td>32.961764</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>185.4</td>\n",
       "      <td>113.30</td>\n",
       "      <td>679</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0.406944</td>\n",
       "      <td>44</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>37.20</td>\n",
       "      <td>85.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>191.0</td>\n",
       "      <td>146.0</td>\n",
       "      <td>191.0</td>\n",
       "      <td>146.0</td>\n",
       "      <td>37.40</td>\n",
       "      <td>37.20</td>\n",
       "      <td>85.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>191.0</td>\n",
       "      <td>191.0</td>\n",
       "      <td>191.0</td>\n",
       "      <td>191.0</td>\n",
       "      <td>259.0</td>\n",
       "      <td>184.0</td>\n",
       "      <td>4.4</td>\n",
       "      <td>4.4</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1000</td>\n",
       "      <td>136.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>51361</td>\n",
       "      <td>68371</td>\n",
       "      <td>20639</td>\n",
       "      <td>157</td>\n",
       "      <td>70.0</td>\n",
       "      <td>19.295957</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>177.8</td>\n",
       "      <td>61.00</td>\n",
       "      <td>697</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0.977083</td>\n",
       "      <td>38</td>\n",
       "      <td>211.09</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>36.50</td>\n",
       "      <td>78.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>36.60</td>\n",
       "      <td>36.50</td>\n",
       "      <td>78.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>4.1</td>\n",
       "      <td>4.1</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>751</td>\n",
       "      <td>350.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>51362</td>\n",
       "      <td>19544</td>\n",
       "      <td>116026</td>\n",
       "      <td>60</td>\n",
       "      <td>54.0</td>\n",
       "      <td>27.900747</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>180.3</td>\n",
       "      <td>90.70</td>\n",
       "      <td>538</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.172917</td>\n",
       "      <td>20</td>\n",
       "      <td>703.03</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>189.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>144.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>184.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>181.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>232.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>232.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>35.10</td>\n",
       "      <td>34.50</td>\n",
       "      <td>112.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>183.0</td>\n",
       "      <td>156.0</td>\n",
       "      <td>183.0</td>\n",
       "      <td>156.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>3.7</td>\n",
       "      <td>3.7</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>320</td>\n",
       "      <td>320.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>51363</td>\n",
       "      <td>85588</td>\n",
       "      <td>102404</td>\n",
       "      <td>196</td>\n",
       "      <td>85.0</td>\n",
       "      <td>39.414062</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>100.90</td>\n",
       "      <td>809</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.031944</td>\n",
       "      <td>15</td>\n",
       "      <td>106.01</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>36.70</td>\n",
       "      <td>84.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>163.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>119.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>119.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>37.10</td>\n",
       "      <td>36.70</td>\n",
       "      <td>66.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>119.0</td>\n",
       "      <td>119.0</td>\n",
       "      <td>119.0</td>\n",
       "      <td>119.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>3.9</td>\n",
       "      <td>3.9</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1486</td>\n",
       "      <td>396.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12835</th>\n",
       "      <td>64194</td>\n",
       "      <td>79880</td>\n",
       "      <td>56511</td>\n",
       "      <td>19</td>\n",
       "      <td>39.0</td>\n",
       "      <td>23.147277</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>163.0</td>\n",
       "      <td>61.50</td>\n",
       "      <td>657</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.155556</td>\n",
       "      <td>39</td>\n",
       "      <td>301.01</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>36.33</td>\n",
       "      <td>98.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>159.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>159.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>37.38</td>\n",
       "      <td>36.33</td>\n",
       "      <td>63.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>6.4</td>\n",
       "      <td>5.5</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2227</td>\n",
       "      <td>465.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12836</th>\n",
       "      <td>64195</td>\n",
       "      <td>97405</td>\n",
       "      <td>32055</td>\n",
       "      <td>136</td>\n",
       "      <td>79.0</td>\n",
       "      <td>27.759515</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>175.5</td>\n",
       "      <td>85.50</td>\n",
       "      <td>374</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.195139</td>\n",
       "      <td>10</td>\n",
       "      <td>107.01</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>36.30</td>\n",
       "      <td>77.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>37.70</td>\n",
       "      <td>36.30</td>\n",
       "      <td>67.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>366</td>\n",
       "      <td>366.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12837</th>\n",
       "      <td>64196</td>\n",
       "      <td>31970</td>\n",
       "      <td>117733</td>\n",
       "      <td>70</td>\n",
       "      <td>56.0</td>\n",
       "      <td>28.331661</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>172.7</td>\n",
       "      <td>84.50</td>\n",
       "      <td>451</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0.012500</td>\n",
       "      <td>36</td>\n",
       "      <td>403.01</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>36.60</td>\n",
       "      <td>83.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>37.10</td>\n",
       "      <td>36.60</td>\n",
       "      <td>78.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>161.0</td>\n",
       "      <td>146.0</td>\n",
       "      <td>4.1</td>\n",
       "      <td>4.1</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1571</td>\n",
       "      <td>366.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12838</th>\n",
       "      <td>64197</td>\n",
       "      <td>76051</td>\n",
       "      <td>93359</td>\n",
       "      <td>189</td>\n",
       "      <td>79.0</td>\n",
       "      <td>24.578812</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>170.2</td>\n",
       "      <td>71.20</td>\n",
       "      <td>543</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.331944</td>\n",
       "      <td>29</td>\n",
       "      <td>1405.05</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>164.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>35.80</td>\n",
       "      <td>101.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>36.60</td>\n",
       "      <td>35.80</td>\n",
       "      <td>101.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>335</td>\n",
       "      <td>328.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12839</th>\n",
       "      <td>64198</td>\n",
       "      <td>84008</td>\n",
       "      <td>107666</td>\n",
       "      <td>204</td>\n",
       "      <td>67.0</td>\n",
       "      <td>26.299440</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>177.8</td>\n",
       "      <td>83.14</td>\n",
       "      <td>426</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0.029167</td>\n",
       "      <td>9</td>\n",
       "      <td>104.01</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>119.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>155.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>36.70</td>\n",
       "      <td>103.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>37.20</td>\n",
       "      <td>36.70</td>\n",
       "      <td>101.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>153.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>153.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>4.7</td>\n",
       "      <td>4.7</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>737</td>\n",
       "      <td>291.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12840 rows × 99 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id personal_id_1 personal_id_2 facility_id   age        bmi  \\\n",
       "0      51359         12058         66446          83  37.0        NaN   \n",
       "1      51360         92348         32311         185  60.0  32.961764   \n",
       "2      51361         68371         20639         157  70.0  19.295957   \n",
       "3      51362         19544        116026          60  54.0  27.900747   \n",
       "4      51363         85588        102404         196  85.0  39.414062   \n",
       "...      ...           ...           ...         ...   ...        ...   \n",
       "12835  64194         79880         56511          19  39.0  23.147277   \n",
       "12836  64195         97405         32055         136  79.0  27.759515   \n",
       "12837  64196         31970        117733          70  56.0  28.331661   \n",
       "12838  64197         76051         93359         189  79.0  24.578812   \n",
       "12839  64198         84008        107666         204  67.0  26.299440   \n",
       "\n",
       "       situation_1  situation_2 ethnicity gender  height  weight icu_id icu_1  \\\n",
       "0                0          0.0         2      1   182.9     NaN     95     1   \n",
       "1                1          0.0         2      1   185.4  113.30    679     2   \n",
       "2                0          1.0         2      1   177.8   61.00    697     1   \n",
       "3                0          1.0         2      1   180.3   90.70    538     0   \n",
       "4                0          1.0         2      0   160.0  100.90    809     0   \n",
       "...            ...          ...       ...    ...     ...     ...    ...   ...   \n",
       "12835            0          0.0         2      0   163.0   61.50    657     0   \n",
       "12836            0          0.0         2      1   175.5   85.50    374     0   \n",
       "12837            0          1.0         2      0   172.7   84.50    451     3   \n",
       "12838            0          1.0         0      0   170.2   71.20    543     2   \n",
       "12839            0          0.0         2      1   177.8   83.14    426     0   \n",
       "\n",
       "      icu_2 icu_3     icu_4 icu_5    icu_6  icu_7  icu_8  \\\n",
       "0         1     5  0.902778    11   501.02      0    0.0   \n",
       "1         0     6  0.406944    44     0.25      0    0.0   \n",
       "2         0     7  0.977083    38   211.09      0    0.0   \n",
       "3         0     5  0.172917    20   703.03      0    0.0   \n",
       "4         0     1  0.031944    15   106.01      0    0.0   \n",
       "...     ...   ...       ...   ...      ...    ...    ...   \n",
       "12835     0     0  0.155556    39   301.01      0    0.0   \n",
       "12836     0     5  0.195139    10   107.01      0    0.0   \n",
       "12837     0     6  0.012500    36   403.01      0    0.0   \n",
       "12838     0     5  0.331944    29  1405.05      1    0.0   \n",
       "12839     0     6  0.029167     9   104.01      0    0.0   \n",
       "\n",
       "       glasgow_coma_scale_1  glasgow_coma_scale_2  glasgow_coma_scale_3  \\\n",
       "0                       4.0                   6.0                   0.0   \n",
       "1                       3.0                   6.0                   0.0   \n",
       "2                       3.0                   5.0                   0.0   \n",
       "3                       4.0                   6.0                   0.0   \n",
       "4                       4.0                   6.0                   0.0   \n",
       "...                     ...                   ...                   ...   \n",
       "12835                   4.0                   6.0                   0.0   \n",
       "12836                   4.0                   6.0                   0.0   \n",
       "12837                   3.0                   6.0                   0.0   \n",
       "12838                   1.0                   1.0                   0.0   \n",
       "12839                   4.0                   6.0                   0.0   \n",
       "\n",
       "       glasgow_coma_scale_4  heart_rate  blood_oxy  arterial_pressure  \\\n",
       "0                       5.0       123.0        0.0               76.0   \n",
       "1                       4.0        60.0        0.0              151.0   \n",
       "2                       1.0       106.0        0.0               58.0   \n",
       "3                       4.0       118.0        0.0              189.0   \n",
       "4                       5.0       165.0        0.0               63.0   \n",
       "...                     ...         ...        ...                ...   \n",
       "12835                   5.0       113.0        0.0               62.0   \n",
       "12836                   5.0       103.0        0.0               46.0   \n",
       "12837                   4.0        93.0        0.0               70.0   \n",
       "12838                   1.0       164.0        0.0               41.0   \n",
       "12839                   5.0       119.0        0.0              155.0   \n",
       "\n",
       "       respiratory_rate   temp  blood_pressure_1  blood_pressure_2  \\\n",
       "0                   4.0  37.00              74.0              56.0   \n",
       "1                   5.0  37.20              85.0              81.0   \n",
       "2                  39.0  36.50              78.0              51.0   \n",
       "3                  53.0    NaN             144.0              73.0   \n",
       "4                  37.0  36.70              84.0              52.0   \n",
       "...                 ...    ...               ...               ...   \n",
       "12835               8.0  36.33              98.0              52.0   \n",
       "12836              13.0  36.30              77.0              43.0   \n",
       "12837              27.0  36.60              83.0              55.0   \n",
       "12838              12.0  35.80             101.0              13.0   \n",
       "12839              42.0  36.70             103.0              61.0   \n",
       "\n",
       "       blood_pressure_3  blood_pressure_4  v1_heartrate_max     v2     v3  \\\n",
       "0                  74.0              56.0             120.0  103.0   93.0   \n",
       "1                  85.0              81.0              83.0   68.0  132.0   \n",
       "2                  78.0              51.0              87.0   69.0   98.0   \n",
       "3                 144.0              73.0             118.0   59.0  184.0   \n",
       "4                  84.0              52.0             163.0  114.0   91.0   \n",
       "...                 ...               ...               ...    ...    ...   \n",
       "12835              98.0              52.0             111.0   84.0  106.0   \n",
       "12836              77.0              43.0              99.0   69.0   82.0   \n",
       "12837              83.0              55.0              89.0   71.0   98.0   \n",
       "12838             101.0              13.0             162.0  102.0  104.0   \n",
       "12839             103.0              61.0             110.0   93.0  120.0   \n",
       "\n",
       "          v4     v5     v6    v7    v8     v9    v10    v11    v12    v13  \\\n",
       "0       74.0   93.0   74.0  19.0   6.0   99.0   90.0  127.0  106.0  127.0   \n",
       "1      107.0  132.0  107.0  14.0  11.0   97.0   92.0  191.0  146.0  191.0   \n",
       "2       73.0   98.0   73.0  20.0  14.0  100.0  100.0  127.0  103.0  127.0   \n",
       "3       81.0  181.0   81.0  53.0   0.0  100.0   94.0  232.0  101.0  232.0   \n",
       "4       63.0   91.0   63.0  32.0  18.0   98.0   89.0  119.0   90.0  119.0   \n",
       "...      ...    ...    ...   ...   ...    ...    ...    ...    ...    ...   \n",
       "12835   62.0  106.0   62.0  21.0  10.0   97.0   88.0  159.0   85.0  159.0   \n",
       "12836   51.0   82.0   51.0  19.0  14.0   97.0   89.0  108.0   77.0  108.0   \n",
       "12837   70.0   98.0   70.0  26.0  13.0  100.0   92.0  145.0  113.0  145.0   \n",
       "12838   22.0  104.0   22.0  16.0  12.0  100.0    7.0  135.0   43.0  135.0   \n",
       "12839   69.0  120.0   69.0  37.0  10.0  100.0   87.0  160.0   90.0  160.0   \n",
       "\n",
       "         v14    v15    v16     w1    w2     w3    w4     w5     w6     w7  \\\n",
       "0      106.0  37.30  36.90   65.0  60.0   65.0  60.0  112.0  104.0   84.0   \n",
       "1      146.0  37.40  37.20   85.0  85.0   85.0  85.0   68.0   68.0  132.0   \n",
       "2      103.0  36.60  36.50   78.0  78.0   78.0  78.0   87.0   87.0   98.0   \n",
       "3      101.0  35.10  34.50  112.0  95.0  112.0  95.0  102.0   88.0  136.0   \n",
       "4       90.0  37.10  36.70   66.0  66.0   66.0  66.0  160.0  144.0   77.0   \n",
       "...      ...    ...    ...    ...   ...    ...   ...    ...    ...    ...   \n",
       "12835   85.0  37.38  36.33   63.0  54.0   63.0  54.0  103.0  100.0   75.0   \n",
       "12836   77.0  37.70  36.30   67.0  59.0   67.0  59.0   74.0   69.0   74.0   \n",
       "12837  113.0  37.10  36.60   78.0  78.0   78.0  78.0   81.0   81.0   94.0   \n",
       "12838   43.0  36.60  35.80  101.0  79.0  101.0  79.0  125.0  102.0  104.0   \n",
       "12839   90.0  37.20  36.70  101.0  76.0  101.0  76.0  109.0   99.0  114.0   \n",
       "\n",
       "          w8     w9    w10   w11   w12    w13    w14    w15    w16    w17  \\\n",
       "0       84.0   84.0   84.0  19.0  16.0   99.0   92.0  115.0  111.0  115.0   \n",
       "1      132.0  132.0  132.0  11.0  11.0   97.0   97.0  191.0  191.0  191.0   \n",
       "2       98.0   98.0   98.0  14.0  14.0  100.0  100.0  127.0  127.0  127.0   \n",
       "3      116.0  136.0  116.0  29.0  15.0   98.0   97.0  183.0  156.0  183.0   \n",
       "4       77.0   77.0   77.0  27.0  27.0   96.0   96.0  119.0  119.0  119.0   \n",
       "...      ...    ...    ...   ...   ...    ...    ...    ...    ...    ...   \n",
       "12835   68.0   75.0   68.0  17.0  15.0   94.0   90.0  120.0  109.0  120.0   \n",
       "12836   67.0   74.0   67.0  16.0  14.0   97.0   95.0   97.0   90.0   97.0   \n",
       "12837   94.0   94.0   94.0  26.0  26.0   96.0   96.0  145.0  145.0  145.0   \n",
       "12838   89.0  104.0   89.0  16.0  12.0   99.0   56.0  135.0  116.0  135.0   \n",
       "12839  113.0  114.0  113.0  36.0  16.0   98.0   97.0  153.0  122.0  153.0   \n",
       "\n",
       "         w18     x1     x2   x3   x4    x5    x6  aids  cirrhosis  diabetes  \\\n",
       "0      111.0  160.0  122.0  3.5  3.5 -1.00  0.03   0.0        0.0       0.0   \n",
       "1      191.0  259.0  184.0  4.4  4.4  0.05  0.01   0.0        0.0       1.0   \n",
       "2      127.0  113.0   93.0  4.1  4.1  0.13  0.06   0.0        0.0       0.0   \n",
       "3      156.0  101.0  101.0  3.7  3.7  0.03  0.02   0.0        0.0       1.0   \n",
       "4      119.0  110.0  110.0  3.9  3.9  0.15  0.07   0.0        0.0       0.0   \n",
       "...      ...    ...    ...  ...  ...   ...   ...   ...        ...       ...   \n",
       "12835  109.0  117.0   89.0  6.4  5.5  0.03  0.02   0.0        0.0       0.0   \n",
       "12836   90.0  180.0  180.0  4.5  4.5  0.04  0.02   0.0        0.0       0.0   \n",
       "12837  145.0  161.0  146.0  4.1  4.1  0.08  0.03   0.0        0.0       0.0   \n",
       "12838  116.0  134.0  114.0  5.0  4.5  0.71  0.53   0.0        0.0       0.0   \n",
       "12839  122.0  118.0  101.0  4.7  4.7  0.06  0.02   0.0        0.0       0.0   \n",
       "\n",
       "       hepatic_issue  immunosuppression  leukemia  lymphoma  carcinoma  \\\n",
       "0                0.0                0.0       0.0       0.0        0.0   \n",
       "1                0.0                0.0       0.0       0.0        0.0   \n",
       "2                0.0                0.0       0.0       0.0        0.0   \n",
       "3                0.0                0.0       0.0       0.0        0.0   \n",
       "4                0.0                0.0       0.0       0.0        0.0   \n",
       "...              ...                ...       ...       ...        ...   \n",
       "12835            0.0                0.0       0.0       0.0        0.0   \n",
       "12836            0.0                0.0       0.0       0.0        0.0   \n",
       "12837            0.0                0.0       0.0       0.0        0.0   \n",
       "12838            0.0                0.0       0.0       0.0        0.0   \n",
       "12839            0.0                0.0       0.0       0.0        1.0   \n",
       "\n",
       "       CE_facility_id  CE_icu_id  ohe_Cardiovascular  ohe_Gastrointestinal  \\\n",
       "0                 451      451.0                   1                     0   \n",
       "1                1000      136.0                   0                     0   \n",
       "2                 751      350.0                   0                     0   \n",
       "3                 320      320.0                   0                     0   \n",
       "4                1486      396.0                   1                     0   \n",
       "...               ...        ...                 ...                   ...   \n",
       "12835            2227      465.0                   0                     1   \n",
       "12836             366      366.0                   1                     0   \n",
       "12837            1571      366.0                   0                     0   \n",
       "12838             335      328.0                   0                     1   \n",
       "12839             737      291.0                   1                     0   \n",
       "\n",
       "       ohe_Genitourinary  ohe_Gynecological  ohe_Haematologic  \\\n",
       "0                      0                  0                 0   \n",
       "1                      0                  0                 0   \n",
       "2                      0                  0                 0   \n",
       "3                      0                  0                 0   \n",
       "4                      0                  0                 0   \n",
       "...                  ...                ...               ...   \n",
       "12835                  0                  0                 0   \n",
       "12836                  0                  0                 0   \n",
       "12837                  0                  0                 0   \n",
       "12838                  0                  0                 0   \n",
       "12839                  0                  0                 0   \n",
       "\n",
       "       ohe_Hematological  ohe_Metabolic  ohe_Musculoskeletal/Skin  \\\n",
       "0                      0              0                         0   \n",
       "1                      0              0                         0   \n",
       "2                      0              0                         0   \n",
       "3                      0              1                         0   \n",
       "4                      0              0                         0   \n",
       "...                  ...            ...                       ...   \n",
       "12835                  0              0                         0   \n",
       "12836                  0              0                         0   \n",
       "12837                  0              0                         0   \n",
       "12838                  0              0                         0   \n",
       "12839                  0              0                         0   \n",
       "\n",
       "       ohe_Neurologic  ohe_Neurological  ohe_Renal/Genitourinary  \\\n",
       "0                   0                 0                        0   \n",
       "1                   0                 0                        0   \n",
       "2                   0                 0                        0   \n",
       "3                   0                 0                        0   \n",
       "4                   0                 0                        0   \n",
       "...               ...               ...                      ...   \n",
       "12835               0                 0                        0   \n",
       "12836               0                 0                        0   \n",
       "12837               1                 1                        0   \n",
       "12838               0                 0                        0   \n",
       "12839               0                 0                        0   \n",
       "\n",
       "       ohe_Respiratory  ohe_Sepsis  ohe_Trauma  ohe_Undefined Diagnoses  \n",
       "0                    0           1           0                        0  \n",
       "1                    0           0           0                        0  \n",
       "2                    1           0           0                        0  \n",
       "3                    0           0           0                        0  \n",
       "4                    0           0           0                        0  \n",
       "...                ...         ...         ...                      ...  \n",
       "12835                0           0           0                        0  \n",
       "12836                0           0           0                        0  \n",
       "12837                0           0           0                        0  \n",
       "12838                0           0           0                        0  \n",
       "12839                0           0           0                        0  \n",
       "\n",
       "[12840 rows x 99 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_test"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d6bf0e3d-cafd-4788-bfd9-aeea4ceb6f03",
   "metadata": {},
   "source": [
    "def target_encoding(cat_cols, tr_x, tr_y, va_x):#list_cat df*3 => df*2\n",
    "    # クロスバリデーションの中で実行し、出力されたデータでモデル学習する\n",
    "    for c in cat_cols:\n",
    "        # 学習データ全体で各カテゴリにおけるtargetの平均を計算\n",
    "        data_tmp = pd.DataFrame({c: tr_x[c], 'target': tr_y['target_label']})\n",
    "        target_mean = data_tmp.groupby(c)['target'].mean()\n",
    "        # バリデーションデータのカテゴリを置換\n",
    "        va_x.loc[:, c] = va_x[c].map(target_mean)\n",
    "\n",
    "        # 学習データの変換後の値を格納する配列を準備\n",
    "        tmp = np.repeat(np.nan, tr_x.shape[0])\n",
    "        \n",
    "        cv_encoding = list(StratifiedKFold(n_splits=5, shuffle=True, random_state=123).split(tr_x,tr_y['target_label']))\n",
    "        for  nfold in list_nfold:\n",
    "            idx_1, idx_2 = cv_encoding[nfold][0], cv_encoding[nfold][1]\n",
    "            # out-of-foldで各カテゴリにおける目的変数の平均を計算\n",
    "            target_mean = data_tmp.iloc[idx_1].groupby(c)['target'].mean()\n",
    "            # 変換後の値を一時配列に格納\n",
    "            tmp[idx_2] = tr_x[c].iloc[idx_2].map(target_mean)\n",
    "        \n",
    "        tr_x.loc[:, c] = tmp\n",
    "        \n",
    "    return tr_x, va_x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2c34814-99ca-434e-bd84-c60396fc7c40",
   "metadata": {},
   "source": [
    "##　重み調整"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "ed466a1e-19ca-46ed-9dc3-29c5b6eb9595",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.54722226, 0.54722226, 0.54722226, 0.54722226, 0.54722226,\n",
       "       5.794111  , 0.54722226, 0.54722226, 0.54722226, 0.54722226,\n",
       "       0.54722226, 0.54722226, 5.794111  , 0.54722226, 0.54722226,\n",
       "       0.54722226, 0.54722226, 0.54722226, 5.794111  , 0.54722226,\n",
       "       0.54722226, 0.54722226, 0.54722226, 0.54722226, 0.54722226,\n",
       "       0.54722226, 0.54722226, 0.54722226, 0.54722226, 0.54722226],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.utils.class_weight import compute_sample_weight\n",
    "train_weight = compute_sample_weight(class_weight='balanced', y=y_train).astype('float32')\n",
    "train_weight[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "bb857af1-a42d-44b1-b791-e7264eee3876",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# カテゴリカル変数（ラベルエンコードとワンホットエンコードした特徴量）\n",
    "# low_cat_colsは0,1、idsは三つのID、そのほかはOHEの出力0,1\n",
    "cat_feats = low_cat_cols + ids + [c for c in n_train.columns if c.startswith('ohe_')]\n",
    "for cat in cat_feats:\n",
    "    # Category型に変換\n",
    "    n_train[cat] = n_train[cat].astype('category')\n",
    "    n_test[cat] = n_test[cat].astype('category')\n",
    "    \n",
    "\n",
    "N_FOLDS = 5\n",
    "list_nfold=[0,1,2,3,4]\n",
    "oof = np.zeros(len(n_train))\n",
    "pred = np.zeros(len(n_test))\n",
    "fi_df = pd.DataFrame()\n",
    "\n",
    "\n",
    "# 必要に応じてencodeされた特徴量を保存し、あとで読み込めるようにしておく\n",
    "\n",
    "# LightGBMのモデルの定義\n",
    "random_state = 123\n",
    "params = {\n",
    "    'boosting_type' :'gbdt',\n",
    "    'objective' : 'binary',\n",
    "    'metrics' : 'auc',\n",
    "    'learning_rate' : 0.1,\n",
    "    'random_state' : random_state,\n",
    "    'importance_type' : 'gain'\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "574a3de4-b084-4a3a-86cc-20d394acd425",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['personal_id_1', 'personal_id_2', 'facility_id', 'age', 'bmi',\n",
       "       'situation_1', 'situation_2', 'ethnicity', 'gender', 'height', 'weight',\n",
       "       'icu_id', 'icu_1', 'icu_2', 'icu_3', 'icu_4', 'icu_5', 'icu_6', 'icu_7',\n",
       "       'icu_8', 'glasgow_coma_scale_1', 'glasgow_coma_scale_2',\n",
       "       'glasgow_coma_scale_3', 'glasgow_coma_scale_4', 'heart_rate',\n",
       "       'blood_oxy', 'arterial_pressure', 'respiratory_rate', 'temp',\n",
       "       'blood_pressure_1', 'blood_pressure_2', 'blood_pressure_3',\n",
       "       'blood_pressure_4', 'v1_heartrate_max', 'v2', 'v3', 'v4', 'v5', 'v6',\n",
       "       'v7', 'v8', 'v9', 'v10', 'v11', 'v12', 'v13', 'v14', 'v15', 'v16', 'w1',\n",
       "       'w2', 'w3', 'w4', 'w5', 'w6', 'w7', 'w8', 'w9', 'w10', 'w11', 'w12',\n",
       "       'w13', 'w14', 'w15', 'w16', 'w17', 'w18', 'x1', 'x2', 'x3', 'x4', 'x5',\n",
       "       'x6', 'aids', 'cirrhosis', 'diabetes', 'hepatic_issue',\n",
       "       'immunosuppression', 'leukemia', 'lymphoma', 'carcinoma',\n",
       "       'CE_facility_id', 'CE_icu_id', 'ohe_Cardiovascular',\n",
       "       'ohe_Gastrointestinal', 'ohe_Genitourinary', 'ohe_Gynecological',\n",
       "       'ohe_Haematologic', 'ohe_Hematological', 'ohe_Metabolic',\n",
       "       'ohe_Musculoskeletal/Skin', 'ohe_Neurologic', 'ohe_Neurological',\n",
       "       'ohe_Renal/Genitourinary', 'ohe_Respiratory', 'ohe_Sepsis',\n",
       "       'ohe_Trauma', 'ohe_Undefined Diagnoses'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "f34ff520-e41c-4fc8-9627-8b96797de3af",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"None of [Index([('personal_id_1', 'personal_id_2', 'facility_id', 'age', 'bmi', 'situation_1', 'situation_2', 'ethnicity', 'gender', 'height', 'weight', 'icu_id', 'icu_1', 'icu_2', 'icu_3', 'icu_4', 'icu_5', 'icu_6', 'icu_7', 'icu_8', 'glasgow_coma_scale_1', 'glasgow_coma_scale_2', 'glasgow_coma_scale_3', 'glasgow_coma_scale_4', 'heart_rate', 'blood_oxy', 'arterial_pressure', 'respiratory_rate', 'temp', 'blood_pressure_1', 'blood_pressure_2', 'blood_pressure_3', 'blood_pressure_4', 'v1_heartrate_max', 'v2', 'v3', 'v4', 'v5', 'v6', 'v7', 'v8', 'v9', 'v10', 'v11', 'v12', 'v13', 'v14', 'v15', 'v16', 'w1', 'w2', 'w3', 'w4', 'w5', 'w6', 'w7', 'w8', 'w9', 'w10', 'w11', 'w12', 'w13', 'w14', 'w15', 'w16', 'w17', 'w18', 'x1', 'x2', 'x3', 'x4', 'x5', 'x6', 'aids', 'cirrhosis', 'diabetes', 'hepatic_issue', 'immunosuppression', 'leukemia', 'lymphoma', 'carcinoma', 'CE_facility_id', 'CE_icu_id', 'ohe_Cardiovascular', 'ohe_Gastrointestinal', 'ohe_Genitourinary', 'ohe_Gynecological', 'ohe_Haematologic', 'ohe_Hematological', 'ohe_Metabolic', 'ohe_Musculoskeletal/Skin', 'ohe_Neurologic', 'ohe_Neurological', 'ohe_Renal/Genitourinary', 'ohe_Respiratory', 'ohe_Sepsis', 'ohe_Trauma', 'ohe_Undefined Diagnoses')], dtype='object')] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[0;32mIn [87]\u001b[0m, in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m id_train \u001b[38;5;241m=\u001b[39m train[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n\u001b[1;32m      3\u001b[0m y_train \u001b[38;5;241m=\u001b[39m train[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtarget_label\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n\u001b[0;32m----> 6\u001b[0m n_test \u001b[38;5;241m=\u001b[39m \u001b[43mtest\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[43mn_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m      7\u001b[0m id_test \u001b[38;5;241m=\u001b[39m test[[id_train\u001b[38;5;241m.\u001b[39mcolumns]]\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/pandas/core/frame.py:3511\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3509\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[1;32m   3510\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[0;32m-> 3511\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcolumns\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m   3513\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[1;32m   3514\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/pandas/core/indexes/base.py:5782\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   5779\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   5780\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[0;32m-> 5782\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   5784\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[1;32m   5785\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[1;32m   5786\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/pandas/core/indexes/base.py:5842\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   5840\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m use_interval_msg:\n\u001b[1;32m   5841\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[0;32m-> 5842\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   5844\u001b[0m not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[1;32m   5845\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"None of [Index([('personal_id_1', 'personal_id_2', 'facility_id', 'age', 'bmi', 'situation_1', 'situation_2', 'ethnicity', 'gender', 'height', 'weight', 'icu_id', 'icu_1', 'icu_2', 'icu_3', 'icu_4', 'icu_5', 'icu_6', 'icu_7', 'icu_8', 'glasgow_coma_scale_1', 'glasgow_coma_scale_2', 'glasgow_coma_scale_3', 'glasgow_coma_scale_4', 'heart_rate', 'blood_oxy', 'arterial_pressure', 'respiratory_rate', 'temp', 'blood_pressure_1', 'blood_pressure_2', 'blood_pressure_3', 'blood_pressure_4', 'v1_heartrate_max', 'v2', 'v3', 'v4', 'v5', 'v6', 'v7', 'v8', 'v9', 'v10', 'v11', 'v12', 'v13', 'v14', 'v15', 'v16', 'w1', 'w2', 'w3', 'w4', 'w5', 'w6', 'w7', 'w8', 'w9', 'w10', 'w11', 'w12', 'w13', 'w14', 'w15', 'w16', 'w17', 'w18', 'x1', 'x2', 'x3', 'x4', 'x5', 'x6', 'aids', 'cirrhosis', 'diabetes', 'hepatic_issue', 'immunosuppression', 'leukemia', 'lymphoma', 'carcinoma', 'CE_facility_id', 'CE_icu_id', 'ohe_Cardiovascular', 'ohe_Gastrointestinal', 'ohe_Genitourinary', 'ohe_Gynecological', 'ohe_Haematologic', 'ohe_Hematological', 'ohe_Metabolic', 'ohe_Musculoskeletal/Skin', 'ohe_Neurologic', 'ohe_Neurological', 'ohe_Renal/Genitourinary', 'ohe_Respiratory', 'ohe_Sepsis', 'ohe_Trauma', 'ohe_Undefined Diagnoses')], dtype='object')] are in the [columns]\""
     ]
    }
   ],
   "source": [
    "n_train.drop(['personal_id_1', 'personal_id_2', 'facility_id','icu_id'], axis=1)\n",
    "id_train = train[['id']]\n",
    "y_train = train[['target_label']]\n",
    "\n",
    "\n",
    "n_test = test[[n_train.columns]]\n",
    "id_test = test[[id_train.columns]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "e2fc1862-870b-45f6-b6e7-abe048c98475",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cvでの評価用 iuput_yはsereis\n",
    "def train_lgb(input_x,\n",
    "              input_y,\n",
    "              input_id,\n",
    "              params,\n",
    "              list_nfold=[0,1,2,3,4],\n",
    "              n_splits=5,\n",
    "              random_state=123\n",
    "            ):\n",
    "    train_oof = np.zeros(len(input_x))\n",
    "    # foldごとの推論値\n",
    "    metrics = []\n",
    "    imp = pd.DataFrame()\n",
    "    print(input_x.shape)\n",
    "    print(input_y.shape)\n",
    "    \n",
    "            \n",
    "    cv = list(StratifiedKFold(n_splits=N_FOLDS, shuffle=True, random_state=random_state).split(n_train, y_train ))\n",
    "    for  nfold in list_nfold :\n",
    "        print('-'*20, nfold, '-'*20)\n",
    "        # 変数をループしてtarget encoding\n",
    "        idx_tr, idx_va = cv[nfold][0], cv[nfold][1]\n",
    "        x_tr, y_tr = input_x.loc[idx_tr, :], input_y.loc[idx_tr, :]\n",
    "        x_va, y_va = input_x.loc[idx_va, :], input_y.loc[idx_va, :]\n",
    "        #CV内でCVしてtargetencording\n",
    "        # x_tr, x_va = target_encoding(cat_cols, x_tr, y_tr, x_va)\n",
    "        train_weight = compute_sample_weight(class_weight='balanced', y=y_tr).astype('float32')\n",
    "        \n",
    "        # print(x_tr)\n",
    "        print(x_tr.shape, y_tr.shape)\n",
    "        print(x_va.shape, y_va.shape)\n",
    "        print('y_train:{:.3f}, y_tr:{:.3f}, y_va{:.3f}'.\n",
    "          format(y_train['target_label'].mean(), y_tr['target_label'].mean(), y_va['target_label'].mean(),))\n",
    "\n",
    "\n",
    "        model = lgb.LGBMClassifier(**params)\n",
    "        model.fit(x_tr,\n",
    "                  y_tr,\n",
    "                  eval_set=[(x_tr,y_tr),(x_va,y_va)],\n",
    "                  early_stopping_rounds=100,\n",
    "                  verbose=100,\n",
    "                  sample_weight = train_weight\n",
    "                  \n",
    "                 )\n",
    "        # モデルの保存\n",
    "        fname_lgb = 'model/lgb/model_lgb_fold{}.pickle'.format(nfold)\n",
    "        with open(fname_lgb, 'wb')as f:\n",
    "            pickle.dump(model, f, protocol=4)\n",
    "            \n",
    "        # 評価\n",
    "        y_tr_pred = model.predict_proba(x_tr)[:,1]\n",
    "        y_va_pred = model.predict_proba(x_va)[:,1]\n",
    "        metric_tr = roc_auc_score(y_tr, y_tr_pred)\n",
    "        metric_va = roc_auc_score(y_va, y_va_pred)\n",
    "        print('[auc] tr: {:.2f}, va: {:2f}'.\n",
    "             format(metric_tr, metric_va))\n",
    "        metrics.append([nfold, metric_tr, metric_va])\n",
    "        \n",
    "        # oof\n",
    "        train_oof[idx_va] = y_va_pred\n",
    "        \n",
    "        # imp\n",
    "        _imp = pd.DataFrame({'col':input_x.columns, 'imp':model.feature_importances_,'nfold':nfold})\n",
    "        imp = pd.concat([imp, _imp], axis=0, ignore_index=False)\n",
    "\n",
    "    print('-'*20, 'result', '-'*20)\n",
    "    \n",
    "    # metrix出力\n",
    "    metrics = np.array(metrics)\n",
    "    print(metrics)\n",
    "    print('[cv] tr: {:.2f}+-{:.2f}, va: {:.2f}'.format(\n",
    "        metrics[:,1].mean(), metrics[:,1].std(),\n",
    "        metrics[:,2].mean(), metrics[:,2].std()\n",
    "    ))\n",
    "    print('[oof] {:.4f}'.format(\n",
    "        roc_auc_score(input_y, train_oof)))\n",
    "    # oof出力  \n",
    "    train_oof = pd.concat([\n",
    "        input_id,\n",
    "        pd.DataFrame({'pred':train_oof})]\n",
    "        ,axis=1)\n",
    "    \n",
    "    # imp出力\n",
    "    imp = imp.groupby('col')['imp'].agg(['mean', 'std']).reset_index(drop=False)\n",
    "    imp.columns = ['col', 'imp', 'imp_std']\n",
    "\n",
    "    print('Done')\n",
    "    \n",
    "    return train_oof, imp, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "7f2cb4c8-75ff-42f8-b1ec-6681cb471f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_train = n_train[['id']]\n",
    "n_train = n_train.drop(['id'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "039c7819-ac5c-4d28-85ae-83127e90172a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(51359, 98)\n",
      "(51359, 1)\n",
      "-------------------- 0 --------------------\n",
      "(41087, 98) (41087, 1)\n",
      "(10272, 98) (10272, 1)\n",
      "y_train:0.086, y_tr:0.086, y_va0.086\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "DataFrame.dtypes for data must be int, float or bool.\nDid not expect the data types in the following fields: facility_id, icu_id",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [74]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m train_oof, imp, metrics \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_lgb\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mid_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43mlist_nfold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m123\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [72]\u001b[0m, in \u001b[0;36mtrain_lgb\u001b[0;34m(input_x, input_y, input_id, params, list_nfold, n_splits, random_state)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124my_train:\u001b[39m\u001b[38;5;132;01m{:.3f}\u001b[39;00m\u001b[38;5;124m, y_tr:\u001b[39m\u001b[38;5;132;01m{:.3f}\u001b[39;00m\u001b[38;5;124m, y_va\u001b[39m\u001b[38;5;132;01m{:.3f}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[1;32m     33\u001b[0m   \u001b[38;5;28mformat\u001b[39m(y_train[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtarget_label\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmean(), y_tr[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtarget_label\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmean(), y_va[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtarget_label\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmean(),))\n\u001b[1;32m     36\u001b[0m model \u001b[38;5;241m=\u001b[39m lgb\u001b[38;5;241m.\u001b[39mLGBMClassifier(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams)\n\u001b[0;32m---> 37\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_tr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[43m          \u001b[49m\u001b[43my_tr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[43m          \u001b[49m\u001b[43meval_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_tr\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_tr\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_va\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_va\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[43m          \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[43m          \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[43m          \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtrain_weight\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[43m          \u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[43m         \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;66;03m# モデルの保存\u001b[39;00m\n\u001b[1;32m     46\u001b[0m fname_lgb \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel/lgb/model_lgb_fold\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.pickle\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(nfold)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/lightgbm/sklearn.py:967\u001b[0m, in \u001b[0;36mLGBMClassifier.fit\u001b[0;34m(self, X, y, sample_weight, init_score, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_metric, early_stopping_rounds, verbose, feature_name, categorical_feature, callbacks, init_model)\u001b[0m\n\u001b[1;32m    964\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    965\u001b[0m             valid_sets[i] \u001b[38;5;241m=\u001b[39m (valid_x, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_le\u001b[38;5;241m.\u001b[39mtransform(valid_y))\n\u001b[0;32m--> 967\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_y\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minit_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minit_score\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalid_sets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    968\u001b[0m \u001b[43m            \u001b[49m\u001b[43meval_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_names\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_sample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_sample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    969\u001b[0m \u001b[43m            \u001b[49m\u001b[43meval_class_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_class_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_init_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_init_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    970\u001b[0m \u001b[43m            \u001b[49m\u001b[43meval_metric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_metric\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    971\u001b[0m \u001b[43m            \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeature_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeature_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcategorical_feature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcategorical_feature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    972\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minit_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minit_model\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    973\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/lightgbm/sklearn.py:748\u001b[0m, in \u001b[0;36mLGBMModel.fit\u001b[0;34m(self, X, y, sample_weight, init_score, group, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_group, eval_metric, early_stopping_rounds, verbose, feature_name, categorical_feature, callbacks, init_model)\u001b[0m\n\u001b[1;32m    745\u001b[0m evals_result \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    746\u001b[0m callbacks\u001b[38;5;241m.\u001b[39mappend(record_evaluation(evals_result))\n\u001b[0;32m--> 748\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_Booster \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    749\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    750\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_set\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    751\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_boost_round\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_estimators\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    752\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalid_sets\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalid_sets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    753\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalid_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    754\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    755\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_metrics_callable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    756\u001b[0m \u001b[43m    \u001b[49m\u001b[43minit_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minit_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    757\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeature_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeature_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    758\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\n\u001b[1;32m    759\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    761\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m evals_result:\n\u001b[1;32m    762\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_evals_result \u001b[38;5;241m=\u001b[39m evals_result\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/lightgbm/engine.py:271\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(params, train_set, num_boost_round, valid_sets, valid_names, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, evals_result, verbose_eval, learning_rates, keep_training_booster, callbacks)\u001b[0m\n\u001b[1;32m    269\u001b[0m \u001b[38;5;66;03m# construct booster\u001b[39;00m\n\u001b[1;32m    270\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 271\u001b[0m     booster \u001b[38;5;241m=\u001b[39m \u001b[43mBooster\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_set\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    272\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_valid_contain_train:\n\u001b[1;32m    273\u001b[0m         booster\u001b[38;5;241m.\u001b[39mset_train_data_name(train_data_name)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/lightgbm/basic.py:2605\u001b[0m, in \u001b[0;36mBooster.__init__\u001b[0;34m(self, params, train_set, model_file, model_str, silent)\u001b[0m\n\u001b[1;32m   2598\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_network(\n\u001b[1;32m   2599\u001b[0m         machines\u001b[38;5;241m=\u001b[39mmachines,\n\u001b[1;32m   2600\u001b[0m         local_listen_port\u001b[38;5;241m=\u001b[39mparams[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlocal_listen_port\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m   2601\u001b[0m         listen_time_out\u001b[38;5;241m=\u001b[39mparams\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtime_out\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m120\u001b[39m),\n\u001b[1;32m   2602\u001b[0m         num_machines\u001b[38;5;241m=\u001b[39mparams[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_machines\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   2603\u001b[0m     )\n\u001b[1;32m   2604\u001b[0m \u001b[38;5;66;03m# construct booster object\u001b[39;00m\n\u001b[0;32m-> 2605\u001b[0m \u001b[43mtrain_set\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconstruct\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2606\u001b[0m \u001b[38;5;66;03m# copy the parameters from train_set\u001b[39;00m\n\u001b[1;32m   2607\u001b[0m params\u001b[38;5;241m.\u001b[39mupdate(train_set\u001b[38;5;241m.\u001b[39mget_params())\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/lightgbm/basic.py:1815\u001b[0m, in \u001b[0;36mDataset.construct\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1812\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_init_score_by_predictor(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_predictor, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata, used_indices)\n\u001b[1;32m   1813\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1814\u001b[0m     \u001b[38;5;66;03m# create train\u001b[39;00m\n\u001b[0;32m-> 1815\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_lazy_init\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlabel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1816\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroup\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1817\u001b[0m \u001b[43m                    \u001b[49m\u001b[43minit_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minit_score\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpredictor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_predictor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1818\u001b[0m \u001b[43m                    \u001b[49m\u001b[43msilent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msilent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeature_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeature_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1819\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mcategorical_feature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcategorical_feature\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1820\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfree_raw_data:\n\u001b[1;32m   1821\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/lightgbm/basic.py:1474\u001b[0m, in \u001b[0;36mDataset._lazy_init\u001b[0;34m(self, data, label, reference, weight, group, init_score, predictor, silent, feature_name, categorical_feature, params)\u001b[0m\n\u001b[1;32m   1472\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpandas_categorical \u001b[38;5;241m=\u001b[39m reference\u001b[38;5;241m.\u001b[39mpandas_categorical\n\u001b[1;32m   1473\u001b[0m     categorical_feature \u001b[38;5;241m=\u001b[39m reference\u001b[38;5;241m.\u001b[39mcategorical_feature\n\u001b[0;32m-> 1474\u001b[0m data, feature_name, categorical_feature, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpandas_categorical \u001b[38;5;241m=\u001b[39m \u001b[43m_data_from_pandas\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1475\u001b[0m \u001b[43m                                                                                     \u001b[49m\u001b[43mfeature_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1476\u001b[0m \u001b[43m                                                                                     \u001b[49m\u001b[43mcategorical_feature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1477\u001b[0m \u001b[43m                                                                                     \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpandas_categorical\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1478\u001b[0m label \u001b[38;5;241m=\u001b[39m _label_from_pandas(label)\n\u001b[1;32m   1480\u001b[0m \u001b[38;5;66;03m# process for args\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/lightgbm/basic.py:594\u001b[0m, in \u001b[0;36m_data_from_pandas\u001b[0;34m(data, feature_name, categorical_feature, pandas_categorical)\u001b[0m\n\u001b[1;32m    592\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m bad_indices:\n\u001b[1;32m    593\u001b[0m     bad_index_cols_str \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(data\u001b[38;5;241m.\u001b[39mcolumns[bad_indices])\n\u001b[0;32m--> 594\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataFrame.dtypes for data must be int, float or bool.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    595\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDid not expect the data types in the following fields: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    596\u001b[0m                      \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbad_index_cols_str\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    597\u001b[0m data \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mvalues\n\u001b[1;32m    598\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m data\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m np\u001b[38;5;241m.\u001b[39mfloat32 \u001b[38;5;129;01mand\u001b[39;00m data\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m np\u001b[38;5;241m.\u001b[39mfloat64:\n",
      "\u001b[0;31mValueError\u001b[0m: DataFrame.dtypes for data must be int, float or bool.\nDid not expect the data types in the following fields: facility_id, icu_id"
     ]
    }
   ],
   "source": [
    "train_oof, imp, metrics = train_lgb(n_train, y_train, id_train, params,list_nfold=[0,1,2,3,4], n_splits=5, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "23fcd33a-1b2e-428a-8489-e172a1058e35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col</th>\n",
       "      <th>imp</th>\n",
       "      <th>imp_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>x5</td>\n",
       "      <td>62574.084443</td>\n",
       "      <td>7121.385684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>icu_5</td>\n",
       "      <td>21806.314151</td>\n",
       "      <td>1133.364213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>x6</td>\n",
       "      <td>13875.056828</td>\n",
       "      <td>7355.532237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>v12</td>\n",
       "      <td>6139.192390</td>\n",
       "      <td>991.547324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>v10</td>\n",
       "      <td>5880.893269</td>\n",
       "      <td>547.386781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>v2</td>\n",
       "      <td>4341.390004</td>\n",
       "      <td>408.773490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>age</td>\n",
       "      <td>3967.040409</td>\n",
       "      <td>486.273704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>v1_heartrate_max</td>\n",
       "      <td>2945.903567</td>\n",
       "      <td>175.966839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>v8</td>\n",
       "      <td>2871.795071</td>\n",
       "      <td>234.575880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>icu_4</td>\n",
       "      <td>2489.834468</td>\n",
       "      <td>202.423160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>facility_id</td>\n",
       "      <td>2474.753121</td>\n",
       "      <td>258.514412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>situation_2</td>\n",
       "      <td>2418.598064</td>\n",
       "      <td>282.285754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>v15</td>\n",
       "      <td>2306.146192</td>\n",
       "      <td>175.737975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>v7</td>\n",
       "      <td>2198.338440</td>\n",
       "      <td>211.935427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>glasgow_coma_scale_4</td>\n",
       "      <td>2164.820952</td>\n",
       "      <td>260.601759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>x2</td>\n",
       "      <td>2033.834335</td>\n",
       "      <td>319.337805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>v16</td>\n",
       "      <td>1930.800368</td>\n",
       "      <td>490.029179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>v4</td>\n",
       "      <td>1876.159342</td>\n",
       "      <td>428.812304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>x4</td>\n",
       "      <td>1841.996026</td>\n",
       "      <td>208.047007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>w12</td>\n",
       "      <td>1840.393556</td>\n",
       "      <td>368.136561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>temp</td>\n",
       "      <td>1782.393879</td>\n",
       "      <td>391.089143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>bmi</td>\n",
       "      <td>1650.117783</td>\n",
       "      <td>203.929033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>icu_id</td>\n",
       "      <td>1625.756248</td>\n",
       "      <td>310.027813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>weight</td>\n",
       "      <td>1465.863939</td>\n",
       "      <td>252.580455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>respiratory_rate</td>\n",
       "      <td>1465.056915</td>\n",
       "      <td>153.891530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>x1</td>\n",
       "      <td>1458.335574</td>\n",
       "      <td>259.161974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>x3</td>\n",
       "      <td>1416.779235</td>\n",
       "      <td>142.729073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>glasgow_coma_scale_2</td>\n",
       "      <td>1377.580001</td>\n",
       "      <td>377.393616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>v11</td>\n",
       "      <td>1351.520428</td>\n",
       "      <td>70.396971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>blood_pressure_2</td>\n",
       "      <td>1168.530694</td>\n",
       "      <td>168.993656</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     col           imp      imp_std\n",
       "96                    x5  62574.084443  7121.385684\n",
       "28                 icu_5  21806.314151  1133.364213\n",
       "97                    x6  13875.056828  7355.532237\n",
       "59                   v12   6139.192390   991.547324\n",
       "57                   v10   5880.893269   547.386781\n",
       "65                    v2   4341.390004   408.773490\n",
       "2                    age   3967.040409   486.273704\n",
       "64      v1_heartrate_max   2945.903567   175.966839\n",
       "71                    v8   2871.795071   234.575880\n",
       "27                 icu_4   2489.834468   202.423160\n",
       "15           facility_id   2474.753121   258.514412\n",
       "55           situation_2   2418.598064   282.285754\n",
       "62                   v15   2306.146192   175.737975\n",
       "70                    v7   2198.338440   211.935427\n",
       "20  glasgow_coma_scale_4   2164.820952   260.601759\n",
       "93                    x2   2033.834335   319.337805\n",
       "63                   v16   1930.800368   490.029179\n",
       "67                    v4   1876.159342   428.812304\n",
       "95                    x4   1841.996026   208.047007\n",
       "76                   w12   1840.393556   368.136561\n",
       "56                  temp   1782.393879   391.089143\n",
       "10                   bmi   1650.117783   203.929033\n",
       "32                icu_id   1625.756248   310.027813\n",
       "91                weight   1465.863939   252.580455\n",
       "53      respiratory_rate   1465.056915   153.891530\n",
       "92                    x1   1458.335574   259.161974\n",
       "94                    x3   1416.779235   142.729073\n",
       "18  glasgow_coma_scale_2   1377.580001   377.393616\n",
       "58                   v11   1351.520428    70.396971\n",
       "7       blood_pressure_2   1168.530694   168.993656"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imp.sort_values('imp', ascending=False)[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "45d10ff8-ecdf-4f3e-9cd8-04493ff127c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.718880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.629117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.328673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.006618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.103982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51354</th>\n",
       "      <td>51354</td>\n",
       "      <td>0.106811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51355</th>\n",
       "      <td>51355</td>\n",
       "      <td>0.520702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51356</th>\n",
       "      <td>51356</td>\n",
       "      <td>0.345277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51357</th>\n",
       "      <td>51357</td>\n",
       "      <td>0.028387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51358</th>\n",
       "      <td>51358</td>\n",
       "      <td>0.012932</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>51359 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id      pred\n",
       "0          0  0.718880\n",
       "1          1  0.629117\n",
       "2          2  0.328673\n",
       "3          3  0.006618\n",
       "4          4  0.103982\n",
       "...      ...       ...\n",
       "51354  51354  0.106811\n",
       "51355  51355  0.520702\n",
       "51356  51356  0.345277\n",
       "51357  51357  0.028387\n",
       "51358  51358  0.012932\n",
       "\n",
       "[51359 rows x 2 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_oof"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "141e3810-a33e-47d6-b44a-5d18fcecc3fc",
   "metadata": {},
   "source": [
    "## 推論"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bda2247c-5492-49c4-a2ac-b0668084ac2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_lgb(input_x,\n",
    "                input_id,\n",
    "                list_nfold=[0,1,2,3,4],\n",
    "               ):\n",
    "    pred = np.zeros((len(input_x), len(list_nfold)))\n",
    "    for nfold in list_nfold:\n",
    "        print('-'*20, nfold, '-'*20)\n",
    "        fname_lgb = 'model/lgb/model_lgb_fold{}.pickle'.format(nfold)\n",
    "        with open(fname_lgb, 'rb')as f:\n",
    "            model = pickle.load(f)\n",
    "        pred[:,nfold] = model.predict_proba(input_x)[:,1]\n",
    "        \n",
    "    pred = pd.concat([\n",
    "        input_id,\n",
    "        pd.DataFrame({'target_label':pred.mean(axis=1)}),], axis=1)\n",
    "    \n",
    "    print('Done')\n",
    "    \n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "787fc33c-3698-4a89-a2e9-9eeb63a8c1ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_test = test[id_train.columns]\n",
    "n_test = n_test.drop(['id'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2c4e1990-cdbc-4d98-a8e1-abedd4bd9556",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- 0 --------------------\n",
      "-------------------- 1 --------------------\n",
      "-------------------- 2 --------------------\n",
      "-------------------- 3 --------------------\n",
      "-------------------- 4 --------------------\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "test_pred_proba = predict_lgb(\n",
    "    n_test,\n",
    "    id_test,\n",
    "    list_nfold=[0,1,2,3,4],\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "19639d0a-dab5-4723-9241-8673a5340b69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>51359</td>\n",
       "      <td>0.605820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>51360</td>\n",
       "      <td>0.633235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>51361</td>\n",
       "      <td>0.623139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>51362</td>\n",
       "      <td>0.522248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>51363</td>\n",
       "      <td>0.594972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>51364</td>\n",
       "      <td>0.528131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>51365</td>\n",
       "      <td>0.624151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>51366</td>\n",
       "      <td>0.546934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>51367</td>\n",
       "      <td>0.566277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>51368</td>\n",
       "      <td>0.553191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>51369</td>\n",
       "      <td>0.562650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>51370</td>\n",
       "      <td>0.603890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>51371</td>\n",
       "      <td>0.621383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>51372</td>\n",
       "      <td>0.626572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>51373</td>\n",
       "      <td>0.616856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>51374</td>\n",
       "      <td>0.547410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>51375</td>\n",
       "      <td>0.509650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>51376</td>\n",
       "      <td>0.609024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>51377</td>\n",
       "      <td>0.618537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>51378</td>\n",
       "      <td>0.573957</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id  target_label\n",
       "0   51359      0.605820\n",
       "1   51360      0.633235\n",
       "2   51361      0.623139\n",
       "3   51362      0.522248\n",
       "4   51363      0.594972\n",
       "5   51364      0.528131\n",
       "6   51365      0.624151\n",
       "7   51366      0.546934\n",
       "8   51367      0.566277\n",
       "9   51368      0.553191\n",
       "10  51369      0.562650\n",
       "11  51370      0.603890\n",
       "12  51371      0.621383\n",
       "13  51372      0.626572\n",
       "14  51373      0.616856\n",
       "15  51374      0.547410\n",
       "16  51375      0.509650\n",
       "17  51376      0.609024\n",
       "18  51377      0.618537\n",
       "19  51378      0.573957"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred_proba[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d5b041b2-6908-46cc-8f39-45283b6f49bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred_proba.to_csv('sub/submission_lgb.csv', index=None, header=True,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b31cad11-42fc-48d7-a3bf-84fa4d8cc753",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id</td>\n",
       "      <td>target_label</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>51359</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>51360</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>51361</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>51362</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12836</th>\n",
       "      <td>64194</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12837</th>\n",
       "      <td>64195</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12838</th>\n",
       "      <td>64196</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12839</th>\n",
       "      <td>64197</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12840</th>\n",
       "      <td>64198</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12841 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0             1\n",
       "0         id  target_label\n",
       "1      51359           0.5\n",
       "2      51360           0.5\n",
       "3      51361           0.5\n",
       "4      51362           0.5\n",
       "...      ...           ...\n",
       "12836  64194           0.5\n",
       "12837  64195           0.5\n",
       "12838  64196           0.5\n",
       "12839  64197           0.5\n",
       "12840  64198           0.5\n",
       "\n",
       "[12841 rows x 2 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample= pd.read_csv(\"data/submission.csv\",header = None)\n",
    "sample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89dd5b16-ac63-495b-894f-5b7fb2038434",
   "metadata": {},
   "source": [
    "## ベースライン"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ad2d4e70-3265-46ff-8266-aca02a5f6150",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "検証データ:  (41087, 98) (41087, 1)\n",
      "ベースライン検証データ:  (10272, 98) (10272, 1)\n",
      "検証データ(train):  (32869, 98) (32869, 1)\n",
      "検証データ(test):  (8218, 98) (8218, 1)\n"
     ]
    }
   ],
   "source": [
    "x_tr, x_va2, y_tr, y_va2 = train_test_split(n_train,\n",
    "                                           y_train,\n",
    "                                           test_size=0.2,\n",
    "                                           shuffle=True,\n",
    "                                           stratify=y_train,\n",
    "                                           random_state=random_state)\n",
    "print('検証データ: ',x_tr.shape, y_tr.shape)\n",
    "print('ベースライン検証データ: ',x_va2.shape, y_va2.shape)\n",
    "\n",
    "x_tr1, x_va1, y_tr1, y_va1 = train_test_split(x_tr,\n",
    "                                              y_tr,\n",
    "                                              test_size=0.2,\n",
    "                                              shuffle=True,\n",
    "                                              stratify=y_tr,\n",
    "                                              random_state=random_state)\n",
    "print('検証データ(train): ',x_tr1.shape, y_tr1.shape)\n",
    "print('検証データ(test): ',x_va1.shape, y_va1.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "37c1ecb8-e36a-4b9a-819b-e97406cca4c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10]\ttraining's auc: 0.895905\tvalid_1's auc: 0.87288\n",
      "[20]\ttraining's auc: 0.916271\tvalid_1's auc: 0.87631\n",
      "[30]\ttraining's auc: 0.931062\tvalid_1's auc: 0.880703\n",
      "[40]\ttraining's auc: 0.941808\tvalid_1's auc: 0.883026\n",
      "[50]\ttraining's auc: 0.950745\tvalid_1's auc: 0.884641\n",
      "[60]\ttraining's auc: 0.958398\tvalid_1's auc: 0.885369\n",
      "[70]\ttraining's auc: 0.965192\tvalid_1's auc: 0.883709\n",
      "[80]\ttraining's auc: 0.970629\tvalid_1's auc: 0.881337\n",
      "[90]\ttraining's auc: 0.975208\tvalid_1's auc: 0.880694\n",
      "[100]\ttraining's auc: 0.979234\tvalid_1's auc: 0.881226\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LGBMClassifier(importance_type=&#x27;gain&#x27;, metrics=&#x27;auc&#x27;, objective=&#x27;binary&#x27;,\n",
       "               random_state=123)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier(importance_type=&#x27;gain&#x27;, metrics=&#x27;auc&#x27;, objective=&#x27;binary&#x27;,\n",
       "               random_state=123)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LGBMClassifier(importance_type='gain', metrics='auc', objective='binary',\n",
       "               random_state=123)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_tr1, x_va1 = target_encoding(cat_cols, x_tr1, y_tr1, x_va1)\n",
    "cat_cols = ['facility_id', 'icu_id']\n",
    "x_va1 = tranform_data_TE(cat_cols, x_va1, y_tr1['target_label'])\n",
    "x_va2 = tranform_data_TE(cat_cols, x_va2, y_tr['target_label'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model = lgb.LGBMClassifier(**params)\n",
    "model.fit(x_tr1,\n",
    "          y_tr1,\n",
    "          eval_set=[(x_tr1,y_tr1),(x_va1,y_va1)],\n",
    "          early_stopping_rounds=100,\n",
    "          verbose=10,\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "942af1ea-93e2-4068-b4f1-0a88104e4b30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[検証データ] auc: 0.8812\n",
      "[ベースライン検証データ] auc: 0.8780\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVoAAADgCAYAAABCd67RAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAAwRElEQVR4nO3deZxU1Z3//9en931vmoYGGqTZBAFFQTEGcUOjcUninug3Lr8kGjNmMTrJ1y2ZxG/GmcxkYsy4jdG4RNFRYlTUhBYXVEBZmk2WBnph6X3f6/P749zGoumGBrqorurP8/GoB1V3Pbdu865T5557SlQVY4wxgRMR7AIYY0y4s6A1xpgAs6A1xpgAs6A1xpgAs6A1xpgAs6A1xpgAs6A1ASci/ywijw3Adu4VkT8HuxyBIiJviMh1A72sCT6xfrRDk4hsB0YAI1S10m/6Z8AMYKyqbj/ENuYBf1bVvECVs8f+7gXGq+q1x2J/h0NEFChQ1S3BLosZfKxGO7QVA1d1vxCRaUDCQO5ARKIGcntHKtjlCPb+TXBZ0A5tTwPf8nt9HfCU/wIiEisiD4rIThHZIyJ/FJF4EUkE3gBGiEij9xjhfb1fKCJ/FpF64PqeX/lF5HQR+VBEakWkRESu761wIjJWRN4VkQYReRvI8ps3T0RKeyy/XUTO9p4ftBwiki8iKiLXecdWKSI/89tWvIj8SURqRGSDiNzRc39+yy71nq723ocrussnIj8Vkd3A/4hIuoi8JiIV3nZfE5E8v+0UisiN3vPrReR9772vEZFiETn/CJcdKyJLvffxHRF56GiaYMzhs6Ad2j4CUkRksohEAlcCPf8DPgBMwDUnjAdGAnerahNwPlCuqkneo9xb52JgIZAGPOO/MREZgwvo/wKyve2u6qN8zwIrcQH7C9wHweHosxx+TgcmAmcBd4vIZG/6PUA+MA44B+izuUJVz/CeTvfeh794r4cDGcAY4Gbc/7f/8V6PBlqA3x+k/LOBTbjj/w3wuIjIESz7LPAJkAncC3zzIPs0AWBBa7prtecAG4Cy7hnef9SbgdtVtVpVG4Bf4QL5YJap6iuq6lPVlh7zrgbeUdXnVLVDVatUdVXPDYjIaOBk4P+qapuqLgX+epjHdrBydLtPVVtUdTWwGpjuTb8c+JWq1qhqKfC7w9w3gA+4xyt/i3esL6lqs/de/gvw5YOsv0NVH1XVLuBPQC6QczjL+r2Pd6tqu6q+Dyw6gmMxR8HajczTwFJgLD2aDXA1zgRgpV9FSoDIQ2yz5CDzRgFb+1GuEUCNV3PutsNbv78OVo5uu/2eNwNJfvv3X78/2+qpQlVbu1+ISALwW2ABkO5NThaRSC8g+yybqjZ75yCpl+UOtmwWUK2qzT2O5XDeR3OUrEY7xKnqDtxFsQuAl3vMrsR9vT1eVdO8R6qqdv9n76vLysG6spQAx/WjaLuAdK8tuNtov+dN+F2485o+sg+jHP3Zv39viiMJpp77/xGumWK2qqYA3U0OfTUHDIRdQIYX8t0sZI8xC1oDcAMwv0ftEVX1AY8CvxWRYQAiMlJEzvMW2QNkikjqYezrGeBsEblcRKJEJFNEZvRcyPsAWAHcJyIxInI6cJHfIp8DcSLyFRGJBn4OxB5GOQ7lBeAu7wLWSODWQyy/B9eeezDJuA+uWhHJwLUDB5Tf+3iv9z6eyv7vozkGLGgNqrpVVVf0MfunwBbgI+/q/Tu4WhmquhF4Dtjm9SAY0Y997cTVnn8EVOMuhE3vY/GrcRd5qnGhtK9pQ1XrgO8Bj+HalZuAXnsFHKH7ve0V4455IdB2kOXvBf7kvQ+X97HMfwDxuG8KHwFvDlRhD+Ea4FSgCvgl8BcOfixmgNkNC8b0g4h8F7hSVQ928SokiMhfgI2qGvAatXGsRmtML0QkV0TmikiEiEzE1cD/N9jlOhIicrKIHOcdywJct7dXglysIcV6HRjTuxjgv3G9MWqB54E/BLNAR2E47kJnJq455Luq+llwizS0WNOBMcYEmDUdGGNMgFnQGmNMgIVNG21aWpqOHz8+2MUImKamJhITEw+9YIiy4wtt4Xx8K1eurFTVnjfDHJawCdqcnBxWrOirK2joKywsZN68ecEuRsDY8YW2cD4+EdlxtNuwpgNjjAmwgAWtiDwhIntFpKiP+SIivxORLSKyRkRO9Jt3nYhs9h72cx3GmJAWyBrtk7hRivpyPlDgPW4GHgbwuwd8NnAKcI+IpPe1EWOMGewC1karqktFJP8gi1wMPKWuI+9HIpImIrnAPOBtVa0GEDey/gLcPfWHpaOjg9LSUlpbWw+98CCXmprKhg0bArLtuLg48vLyiI6ODsj2jRnqgnkxbCT7j/FZ6k3ra/phKy0tJTk5mfz8fPoemD40NDQ0kJycPODbVVWqqqooLS1l7NixA759Y0yI9zoQkZtxzQ5kZ2dTWFi43/zU1FQyMzNpbGwMQukGVldXFw0NDQHZdkxMDLW1tQe8f8dSY2NjUPcfaHZ8Q1swg7aM/QcgzvOmleGaD/ynF/a2AVV9BHgEYOLEidqze8mGDRtISUkZqPIGVaBqtN3i4uKYOXNmwLZ/KOHcPQjs+Ia6YHbvWgR8y+t9MAeoU9VdwGLgXG/A5XTgXG9aSKqtreUPfzj8sUguuOACamtrD7rM3XffzTvvvHOEJTPGHCsBq9GKyHO4mmmW9zPN9wDRAKr6R+B13ADQW3C/1fR/vHnVIvILYLm3qfu7L4yFou6g/d73vrff9M7OTqKi+n77X3/99UNu+/777z/q8hljAi+QvQ6uOsR8BW7pY94TwBOBKNexduedd7J161ZmzJhBdHQ0cXFxpKens3HjRj7//HMuueQSSkpKaG1t5Qc/+AE333wzAPn5+axYsYLGxkbOP/98Zs+ezfLlyxk5ciSvvvoq8fHxXH/99Vx44YV8/etfJz8/n+uuu46//vWvdHR08OKLLzJp0iQqKiq4+uqrKS8v59RTT+Xtt99m5cqVZGVlBfmdMWboCOmLYYfjvr+uY315/YBuc8qIFO656PiDLvPAAw9QVFTEqlWrKCws5Ctf+QpFRUX7rvA/8cQTZGRk0NLSwsknn8zXvvY1MjMz99vG5s2beeyxx3jyySe5/PLLeemll7j22msP2FdWVhaffvopf/jDH3jwwQd57LHHuO+++5g/fz533XUXb775Jo8//vjAvQHGmH6xW3CPsVNOOWW/blS/+93vmD59OnPmzKGkpITNmzcfsM7YsWM54YQTADjppJPYvn17r9u+7LLLDljm/fff58orrwRgwYIFpKfbvR/GHGtDpkZ7qJrnseI/wlFhYSHvvPMOy5YtIyEhgXnz5vV6c0Vs7Bc/7hoZGUlLS0uv2+5eLjIyks7OzgEuuTHmSFmNNsCSk5P77P9aV1dHeno6CQkJbNy4kY8++mjA9z937lxeeOEFAN566y1qamoGfB/GmIMbMjXaYMnMzGTu3LlMnTqV+Ph4cnJy9s1bsGABf/zjH5k8eTITJ05kzpw5A77/e+65h6uuuoqnn36aU089leHDhwe0P64x5kAWtMfAs88+2+v02NhY3njjjV7ndbexZmVlUVRUtK9W/OMf/3jfMk8++eQBywPMmjVr3106qampLF68mKioKJYtW8by5cv3a4owxgSeBW2Y27lzJ5dffjk+n4+YmBgeffTRYBfJmCHHgjbMFRQU8Nln9svSxgSTXQwzxpgAs6A1xpgAs6YDY8yQ1NjWya7aFioa2qhp7qCmuZ29DW3srmthV10r/2duPvMn5Rx6Q/1gQWuMCTtdPmVPfStltS1UNbZT19JOZWM7Wysa2bq3keLKJupbD7ypRwSGJccyPDWe9k7fgJXHgtYYE3I6u3xsr2pmW0Uj5bUtlNe1Ul7bwt76NnbXt7KrroWOLj1gvZyUWMYPS+KrM0YwMi2BEWlxZCfHkpEYQ3pCDBmJMURHDnyLqgXtIJOUlERjYyPl5eXcdtttLFy48IBl5s2bx4MPPsisWbN63cbPfvYznnrqKWpqasLi1yXM0NPc3smWvY1sr2qmtKaZ0poWqhvbqWvpoLqpneLKJtq7vqhxxkZFkJsaR05KHDNHp3FBai6jMuIZmRZPVlIs6YkxZCTEEB8TGZTjsaAdpEaMGNFryPbHRRddxK233kpBQcEAl8qYgdHU1smOqmZ2VjdTUt1MWW0LFY1tVDa0UVbbQmnN/uN5pCdEk5UUS1pCNKMzE5g3MZsJOcmMH5ZEXno8GYkxg/p3AYdO0L5xJ+xeO7DbHD4Nzn/goIvceeedjBo1iltucUPv3nvvvURFRbFkyRJqamro6Ojgl7/8JRdffPF+623fvp0LL7yQoqIiWlpauP7661m/fj2TJk3qc1CZboG4ldeYw+XzKaU1LWze28DWCtcuuq2iieLKJvY2tO23bFJsFMOSY8lMimHm6HSumDWKgpwkxma5IE2MDe2oCu3Sh4ArrriCf/qnf9oXtC+88AKLFy/mtttuIyUlhcrKSubMmcNXv/rVPj+RH374YRISEtiwYQNr1qzhxBNPPJaHYMwBmts72VvfRlVTGxUN7by/o4OP3tjI7roW9tS3safBtZm2dnzx9T4zMYb8rETOmJDN2KxE8jMTGZOZwKj0BFITwvun7odO0B6i5hkoM2fOZO/evZSXl1NRUUF6ejrDhw/n9ttvZ+nSpURERFBWVsaePXsYPnx4r9tYunQpN954IwAnnHDCvrFpjQmUhtYOSqpbKPHaR8tr3aP7a311U/sB68R8XsywlFiGp8QxeXgK8ycOoyAnifHDkhmfnRT2YXowQydog+gb3/gGCxcuZPfu3VxxxRU888wzVFRUsHLlSqKjo8nPz+91HFpjAklVqW/tZEeV+zq/taKJjbvqWVdeT1nt/s1TcdERjEyLZ2R6AlNHpjIyLZ7hKXFkJceSmRjDtqJPufCceUREDN520mCyoD0GrrjiCm666SYqKyt59913eeGFFxg2bBjR0dEsWbKEHTt2HHT9M844gxdffHFfm+2aNWuOUclNqFNVqpva2VXXys7qZjbubmDjrnqKK5sor22hqb1r37IiMDYrkZmj07h69uh9X+tHZSSQnhB90ItNlZvFQvYgLGiPgeOPP56GhgZGjhxJbm4u11xzDRdddBHTpk1j1qxZTJo06aDrf/e73+Xaa69l8uTJTJ48mZNOOumgy99xxx08++yzNDc3k5eXx4033si99947gEdkBqPWji7WlNbx6c4aNu1uYNPuBrZVNu7XThrhhelx2UmcXpDFiNR4RmXEMy47idEZCcRFB6f7U7izoD1G1q79osdDVlYWy5Yt63W57n6v+fn5FBUVARAfH8+TTz7Z7wG7f/Ob3/Cb3/zmKEtsBitVpbyulaKyOjbuamBLRSNb9jayeU8DnT7XST83NY4JOcmcdlwmeenxDE+NJy89nvHDkixMg8CC1phByudT9jS0srOqmR3VzWzc1cDG3fVs2FVPTXPHvuW6A/TMidmcODqdmaPTyEyywd0HEwvaEDZ79mza2vbvj/j0008zbdq0IJXIHClVpay2hc921rK6pJY1pXUUldfR7NeGGhcdwcScZM6dMpypI1M4fmQqk4YnkxBj/40HOztDIezjjz8OdhHMEWrv9LFhVz0rdtSwYns1K3bUUOF14o+JiuD4ESl846Q8CnKSGZ2RwOgMd1Eq0i44haSwD1pVHdS35g0GqgcOvmEGhs+nbK9q4rO9nRR/UMyOqmbWltWxtqxu3+hQozLiOX18FieOTmPGqHQm5SYHZGATEzxhHbRxcXFUVVWRmZlpYdsHVaWqqoq4uLhgFyUs1DS181lJDZ/uqGVVSS2rS2tp6B6O79P1JMREMiU3hW/NGcOM0WnMGpPB8FR778NdWAdtXl4epaWlVFRUBLsoR621tTVgYRgXF0deXl5Ath3OWju6WL+rnrWldawqccFaXNkEQGSEMGl4MhdNH8H0vFQayzZz8dmnkznIBz8xgRHWQRsdHc3YsWODXYwBUVhYyMyZM4NdjCGrobWD9eXurin3qGPz3ka6vO5Uw5JjmTEqjW/MyuPE0emckJe630WqwqZtZFlPgCErrIPWmCPR3N7J+vL6fbXUorI6tlc175uflRTL8SNSOHtyDtPyUpk2MpXc1DirqZo+BTRoRWQB8J9AJPCYqj7QY/4Y4AkgG6gGrlXVUm9eF9Ddy3+nqn41kGU1Q1N1U7vr+L+7ng27Gigqq2NrRSNeRZURqXGckJfG10/K4/gRqRw/IoVhKdamag5PwIJWRCKBh4BzgFJguYgsUtX1fos9CDylqn8SkfnAr4FvevNaVHVGoMpnhqa2zi7Wl9fz/uZK3tm4l9Ultfvm5aTEMnVEKhdMy2XqyFSm56VaqJoBEcga7SnAFlXdBiAizwMXA/5BOwX4ofd8CfBKAMtjhqC65g4+2V7Nsq1VrNxRzfpd9XR0KSIwPS+NH54zgVlj0pmUm0JGYkywi2vCVCCDdiRQ4ve6FJjdY5nVwGW45oVLgWQRyVTVKiBORFYAncADqvpKAMtqwkBVYxvrd+1/waq4sglV95tSM0alccPp45iel8qs/Ayyk+3ilDk2gn0x7MfA70XkemApUAZ033M4RlXLRGQc8A8RWauqW/1XFpGbgZsBsrOzKSwsPGYFP9YaGxvt+HqoavGxsbqLDdU+NlR1UdX6xY0XmXHC6JQILjkumkkZkYxLiyA6og3YDVW7WVc1sOU/FDt/Q1sgg7YMGOX3Os+bto+qluNqtIhIEvA1Va315pV5/24TkUJgJrC1x/qPAI8ATJw4UefNmxeAwxgcCgsLGerHV9HQxnubK3h/SyWfFFfv+wG/9IRo5ozP4cTR6Rw/IoXJuSmkD7JmADt/Q1sgg3Y5UCAiY3EBeyVwtf8CIpIFVKuqD7gL1wMBEUkHmlW1zVtmLmDj/g0hqsrWiiZWldSyprSWlTtqWFdeD7jfnjo5P4Nvzx3L7HEZTB6eYoNOm0EtYEGrqp0iciuwGNe96wlVXSci9wMrVHURMA/4tYgorungFm/1ycB/i4gPiMC10a4/YCcmrOyqa+GT4mre31zJe5sr2V3vft4nMSaSaXmp/OS8iXx5QjZTci1YTWgJaButqr4OvN5j2t1+zxcCC3tZ70PAxvoLc10+5ePiKv62ZhdvrWmm4s1/AJAaH83p47P4UkEWs/LTGZuVZKNWmZAW7IthZogprmzi421VfFJczdLNlVQ2tpEQE8nk9Ai+c9ZETsnPYHJuMlE2epUJIxa0JqBUleLKJv62Zhd/XVPO53vcT/VkJsYwZ1wmF0zLZf6kYXz84XvMOz08xqUwpicLWjOgfD7l870NLN9ew/Liaj4prt7X1npyfjr3ffV45o7P4rjsRBsbwAwZFrTmqDW2dbJk417eKNrF+5srqffGX81JiWX22ExOHpvBWZOGMSItPsglNSY4LGjNEalv7eAfG/by+tpdvPt5BW2dPrKTYzl/ai6njM3glLEZ5KXHW63VGCxozWEoqW7mHxv38s6GPXy8rZr2Lh/DU+K46pTRXDAtl5PGpFvvAGN6YUFr+qSqrCuv5611u3lr/R427m4AYFxWItedNoYFU3OZOSrN+rQacwgWtGY/Pp/yWUktbxbt4o2i3ZTWtBAhMGtMBv98wSTOnpzDuOykYBfTmJBiQWtQVVaV1PLqqnLeLNrN7vpWoiOF08dncdv8As6ekmNDCBpzFCxoh7CS6mZeXVXGy5+Wsa2yiZioCL48IZufTpvIWZNzSImLDnYRjQkLFrRDTF1LB4tWlfG/n5Xx6c5aAGaPzeA7Xz6OBdOGW7gaEwAWtEPE+vJ6nvywmEWry2nt8DFpeDI/XTCJi6bnkpeeEOziGRPWLGjD3N6GVh5cvIkXV5YSHx3JpTPzuGb2aKaOTA120YwZMixow1BNUzvLtlXxwZZKXl1VTmtHFzfMHcv3zyogNd6aBow51ixow0R7p493Nuzh+eUlvLe5AlU3juu8ScP40TkTrEuWMUFkQRviqhrbePqjHTy9bAdVTe3kpsZxy7zxnDkpmxPy0oi24QaNCToL2hBVUt3MI0u38cKKEto6fZw1aRjfPHUMXyrItttgjRlkLGhDzIZd9fzx3a28tmYXEQKXzhzJTV8aR0FOcrCLZozpgwVtCFBViiq7ePzxj3lvcyWJMZF8e24+N5w+juGpccEunjHmECxoB7Gy2hZeXlnKy5+VUVzZSnay8pPzJnLN7NGkJdgtscaECgvaQaastoU31roBXVbuqAHcnVtn5XbwkyvOJDYqMsglNMYcLgvaQaC1o4u31u/hL8t38sGWKgAm56bwo3MmcMnMkYzKSKCwsNBC1pgQZUEbRDuqmnjm4528uKKEmuYORqbFc/vZE7h4xgjysxKDXTxjzACxoA2CkupmfvX6Bt4o2k1khHDulByuOmU0p4/PskG0jQlD/QpaEZkDrFPVBu91CjBZVT8OZOHCTXN7Jw8t2cKj7xUTKcL354/nmtljrOeAMWGuvzXah4ET/V439jLNHMTa0jp+8PxnbKts4tKZI/npgkkWsMYMEf0NWlFV7X6hqj4RsWaHfujo8vHYe8X821ubyEqK5dkbZ3Pa+KxgF8sYcwz1Nyy3ichtuFoswPeAbYEpUnjo6PLx8qel/H7JFkqqW7hg2nB+dek06/9qzBDU36D9DvA74OeAAn8Hbg5UoULdJ8XV/GThanZUNXNCXir3XnQ88ycNQ8QudBkzFPUraFV1L3BlgMsS8to7ffz2nc/547tbGZWewBPXz+LMiRawxgx1/e118D+4mux+VPXbh1hvAfCfQCTwmKo+0GP+GOAJIBuoBq5V1VJv3nW4GjTAL1X1T/0pazCoKm+v38ODb23i8z2NXDFrFP/3oikkxVoztjGm/00Hr/k9jwMuBcoPtoKIRAIPAecApcByEVmkquv9FnsQeEpV/yQi84FfA98UkQzgHmAWLuBXeuvW9LO8x8yqklruWbSO1SW1jM1K5NFvzeKcKTnBLpYxZhDpb9PBS/6vReQ54P1DrHYKsEVVt3nrPA9cDPgH7RTgh97zJcAr3vPzgLdVtdpb921gAfBcf8p7rLy6qoyfLFxDRkIM/+9r0/jaiXlE2UDbxpgejvS7bQEw7BDLjARK/F6XArN7LLMauAzXvHApkCwimX2sO7LnDkTkZryLctnZ2RQWFvb/CI6CqvLKlg5e3drBxPQIvj8zgqSmbbz/XuA6YjQ2Nh6z4wsGO77QFu7Hd7T620bbwBdttArsAe4YgP3/GPi9iFwPLAXKgK7+rqyqjwCPAEycOFHnzZs3AEU6uLLaFu58aQ3vba3k6yfl8atLpxETFfhabGFhIcfi+ILFji+0hfvxHa3+Nh0ke+2mBbg2Wujl4lgPZcAov9d53jT/7ZbjarSISBLwNVWtFZEyYF6PdQv7U9ZA8fmUZz/Zya9f34ACv7hkKtfOHm09Cowxh9TfGu2NwA9wgbcKmAMsA+YfZLXlQIGIjMUF7JXA1T22mwVUq6oPuAvXAwFgMfArEUn3Xp/rzQ+Kj7ZV8cu/raeorJ7Tx2fx68umMSojIVjFMcaEmP620f4AOBn4SFXPFJFJwK8OtoKqdorIrbjQjASeUNV1InI/sEJVF+Fqrb8WEcU1HdzirVstIr/AhTXA/d0Xxo6lLXsb+dfFG1m8bg+5qXH8xxUzuHjGCKvFGmMOS3+DtlVVW0UEEYlV1Y0iMvFQK6nq68DrPabd7fd8IbCwj3Wf4Isa7jG1t76V377zOS+sKCUuKoIfnjOBm740jvgYG3jbGHP4+hu0pSKShut+9baI1AA7AlWoYNpb38olD31ARWMb35wzhlvnjycrKTbYxTLGhLD+Xgy71Ht6r4gsAVKBNwNWqiBp7ejipqdWUNPcwUvfPY0T8tKCXSRjTBg47H60qvpuIAoSbD6f8qMXVrOmrI7/vvYkC1ljzICx25iAprZO7nhpDX9bu4u7zp/EuccPD3aRjDFhZMiPevLpzhp++JdV7Khu5vvzx3PTl8YFu0jmWFCF1lqo3wXNldBcDS010N4IbY3u344W9wCIT4O4NEjIgKRhkJAFUXEQEQEI+Dqhsw3UB9EJEB0PItDeDO2NZFZ+DKt3u+2NPAmGT3PzzZAwpIN2yaa93PinFQxPieP5m+Ywe1xmsItkeuPzQcMuqN0JdSXQVOmFlEBEJERGQ2SMC77oBIiOg45WLzTroaXWhWhTJdSXQn25e3Q0973PqHiISXDb6w7l9sYjPoRpAEV+E9JGQ8G5kDgMYpPcsTTucY/2JpAI99Au6Op0AZ40DFJHQXKOWx6FmETImQaZx7n3AsDX9cVzMygM2aBt7ejinlfXMTYrkZe/dxopcdHBLtLQ4OtyIVe704VnRzN0tDB6x1r4+1KvNtkEHU3uee1OqNkOXW1Ht9/IWEjMgpSRkDMVCs6DlFxIznUBFp/haquxyS5cewuqrg5X823aC00V7rX63CMyxgU+Ap2t7hhQiEmGmARWrN3ErNPmufDc/h5s/Busfn7/8I6MgaQcF56qLmQl8ovtlq1w++1NdCLEpUBrnXtPE7Jg2GTIHO8+lDpaXa07JsEti35Rix91Cpx2G0TZr38EypAN2sffL2ZndTNP33CKhexA6erwQnSHC8c962DXathdBJ3eV3BfF73dvT0OYEeUC5mYJBd2MYmQPQEmnAcZY10tMG0MJHjfPLrDqKsDutq9gGt2/0bHuZCLTXZf+6Pjj/74IqNdbTL58IfBbNze6Wqd4I7lxG+5512dLmzVB/Hph25O6Gj5ImwlwoXl7rWwe43bTlyae9/qy6FiI2xY5JaLinMfHh0t3ocA7sMlJgE2L4ail+Di37tmjf321wptDe599nV524p12+uucauPqI5GVxb1ufPh63TveeIg+n081aA11wzJoN1d18pDS7Zw7pQcvlSQHeziBE9zNVRu/uLrdONerzbZ3S6ZDgnprlbV3l3TbHb/+TpbvH+9/4gNu9z6/iEanQDDT4DpV7raFkBEFKSMcKGZPMIL1kSWLlvBGfPPGXrtlpFR7oOgv6Lj3XvXLTUPck8ArjnyMmx6A167HR47232IiXeNvLX+iw/IQzgd4INeZqTkwciZkDoaUBd2UbHuA7D720NMggvubh0t7u+pYbf7+4qMcX83bQ1ee3qNC3L1ga/D1eJb66Cz3ft7SmDfN4vOVtd23tnmlo2Mce9hVJzbpkS6D4vudnnU2180LPjVFx+IR2lIBu0Db2yg06f8/CtTgl2UgeXrcjXJ2p3udUSk++Os/NwFalOF+8PraIGaHe4rsL/IWNdeGO2N49Bc7b7Cg/vP113TjI5zbZjRce4PNjHbXdxJGeG+mqfnQ/oY157Yz7ZCX2TM0AvZwWLi+TDmNFj2B9dGrD5AIS7VfdjGprjzKBFuXme7C2DVfW3JW7YVM75gonsdGeWCqrUOyj+DspWw5R/esuL+/nwdhy5XVLwLRV+n+8YSk+RqyPEZLqxFXFhmjHM1+choVxFo99reo+K+qH1Hxbr5nW1u/52tfrX0SPd3H5PoytjV7mrlWRMG7C0eckH74dZKXllVzq1njmd0ZogNDNPZBtXF7ivh7rWwd70Lw64298d1sLbMpOGQPPyLC0YF50L2RPdIHeVCMi71wLDrbPuiFmJBGL7iUuHMIx+3qbSjkPFz5vV/hc42V4vsaNq/d4eI+xtNHu4CPkz+5oZU0Da3d3LnS2vJz0zgljPHB7s4B9fZ7mqiOz6EHe8zZ+syKKxg31dziYSsAnchJzYZUmKh4BzInuTaALu/EkXFu7bBw/l66i/Kbj82ARAV6/1tDY2ePkMqaP/trc/ZWd3MX26eE5gBYnw+qN0OezdCxQao2OQezdVw1t1wwjcOXEfVu2i0ytVUKza5r/m1O11QAqSOoi51InGTv+1CM6sAsie7r+7GmEFvyATtpztreOKDYq6dM3rg+sv6fK79aVshlHwEJZ+4fpvdUka6r+YAL9/oaqjz7nJtTjuXwedvwsbXvmhTjYx17UIjZsC0r0NmAYyeA+lj2FBYSI6NYG9MSBoSQdvU1slPXlxNbkocP10w6fBWrtgEVVvcFfXmKheSvi5o3A2fL3YXD8DVMKd+DUbMhGFTXMB2X2nvbHdXdZf+Bja97tpZO5pcsB53JpzxExgz111Eso7mxoSdsA9aVeWOl9ZQXNnEn2+YTXJ/+syqQvFSeP/fXW21N7EpcNx8mPQVGH+26+zel6gY10dx2GRY87zr7jT+bBh7hndXkDEmnIV90D7+fjF/W7OLny6YxGnjD9F52tflOnh/8Dso/9TdpXP2vTDuTNeFKSHzyK++i8Bpt7qHMWZICeug/WhbFb9+YyMLjh/Od77cx2AxTZWubbV0Oax72XWRyhgHF/4Wpl9tF5yMMUctrIP239/+nBFpcfzrN07o/Xe+NvwVXrjOXd2PiIK8U+CcX7jmAGsrNcYMkLAN2i6fUlRWxzdOyuu9Xba9Gd6407WbXvAg5E73bt0zxpiBFbZBW1zZSHN7F9P6+qWED//L3eN/2SMw5tRjWjZjzNAStr+wsLasDoBpI1MPnFlXBh/8B0y5GPLnHtuCGWOGnPAN2tJ64qIjOC478cCZf7/P9TA45/5jXzBjzJATtkFbVFbHlNwUoiJ7HOL6RbDmL3DqLe4GAWOMCbCwDFqfT1lXXndgs0HJcnj5Jte74Mt3BKdwxpghJyyDdltlE03tXUz1D9rqbfDclW74taueG5gR940xph/CMmiLui+E5XlBW74KnrrE9Ze95qXB9fMaxpiwF5ZBu7asjrjoCMZnJbhuXI+d7QaDuWYhZA3ycWiNMWEnLPvRri2rY3JuClFv/xw+fhgmXQhf/a+DD/xijDEBEtAarYgsEJFNIrJFRO7sZf5oEVkiIp+JyBoRucCbni8iLSKyynv8sb/79PmU9eX1TBuRAkULYfJFcMWfLWSNMUETsBqtiEQCDwHnAKXAchFZpKrr/Rb7OfCCqj4sIlOA14F8b95WVZ1xuPstrmqisa2TU1Or3I8Rjh+Cv6xqjBlUAlmjPQXYoqrbVLUdeB64uMcyCnijY5MKlB/tTrsvhM3wrXMT8k8/2k0aY8xRCWTQjgRK/F6XetP83QtcKyKluNrs9/3mjfWaFN4VkS/1d6erS+qIjYogp3qF++XXjD6GRzTGmGMk2BfDrgKeVNV/E5FTgadFZCqwCxitqlUichLwiogcr6r1/iuLyM3AzQDZ2dkUFhZSWNRCfpLSsXkJtWlT2fDuu8f6mAKisbGRwsLCYBcjYOz4Qlu4H9/RCmTQlgGj/F7nedP83QAsAFDVZSISB2Sp6l6gzZu+UkS2AhOAFf4rq+ojwCMAEydO1NmnfYmdby3mpydHEbu6hpyTLyXn5HkBOLRjr7CwkHlh/OOMdnyhLdyP72gFsulgOVAgImNFJAa4EljUY5mdwFkAIjIZiAMqRCTbu5iGiIwDCoBth9rh6tJaOn3K6TGb3ARrnzXGDAIBq9GqaqeI3AosBiKBJ1R1nYjcD6xQ1UXAj4BHReR23IWx61VVReQM4H4R6QB8wHdUtfpQ+1y5owaA45pWu9/4ypoQmIMzxpjDENA2WlV9HXeRy3/a3X7P1wMHDAirqi8BLx3u/lbuqGF8diIxpctgzGnWrcsYMyiE1S24K3fUcM6IVvfLCWOs2cAYMzgEu9fBgOnwQVtLB2fGeU259ssJxphBImxqtK2dCsCU5hWQkAXZk4NcImOMccImaNu6IDshksSSJTDhPIgIm0MzxoS4sEmjti7l68PKkdY6F7TGGDNIhE3QdvjgvOhPISIajpsf7OIYY8w+YRO0ABPrP3Q3KcQmB7soxhizT9gE7fC4TuLrtsLE84NdFGOM2U/YBG0Kze6Jtc8aYwaZsAnaqM5m16UrPT/YRTHGmP2ETdBGdrVYbdYYMyiFTdCCWvusMWZQCpugbYnPhbyTg10MY4w5QNgEbWdUIkREBrsYxhhzgLAJWmOMGawsaI0xJsAsaI0xJsAsaI0xJsAsaI0xJsAsaI0xJsAsaI0xJsAsaI0xJsAsaI0xJsAsaI0xJsAsaI0xJsAsaI0xJsAsaI0xJsAsaI0xJsAsaI0xJsAsaI0xJsACGrQiskBENonIFhG5s5f5o0VkiYh8JiJrROQCv3l3eettEhH7MTBjTMiKCtSGRSQSeAg4BygFlovIIlVd77fYz4EXVPVhEZkCvA7ke8+vBI4HRgDviMgEVe0KVHmNMSZQAlmjPQXYoqrbVLUdeB64uMcyCqR4z1OBcu/5xcDzqtqmqsXAFm97xhgTcgIZtCOBEr/Xpd40f/cC14pIKa42+/3DWNcYY0JCwJoO+ukq4ElV/TcRORV4WkSm9ndlEbkZuBkgOzubwsLCwJRyEGhsbLTjC2F2fENbIIO2DBjl9zrPm+bvBmABgKouE5E4IKuf66KqjwCPAIhIw5lnnrlpwEo/+GQBlcEuRADZ8YW2cD6+iUe7gUAG7XKgQETG4kLySuDqHsvsBM4CnhSRyUAcUAEsAp4VkX/HXQwrAD45xP42qeqsASz/oCIiK+z4QpcdX+gSkRVHu42ABa2qdorIrcBiIBJ4QlXXicj9wApVXQT8CHhURG7HXRi7XlUVWCciLwDrgU7gFutxYIwJVQFto1XV13EXufyn3e33fD0wt491/wX4l0CWzxhjjoVwujPskWAXIMDs+EKbHV/oOupjE/dN3RhjTKCEU43WGGMGpbAI2kONqRBqRGSUNwbEehFZJyI/8KZniMjbIrLZ+zc92GU9UiIS6Y1x8Zr3eqyIfOydw7+ISEywy3ikRCRNRBaKyEYR2SAip4bZubvd+7ssEpHnRCQulM+fiDwhIntFpMhvWq/nS5zfece5RkRO7M8+Qj5o/cZUOB+YAlzljZUQyjqBH6nqFGAOcIt3THcCf1fVAuDv3utQ9QNgg9/r/wf8VlXHAzW4Ptah6j+BN1V1EjAdd5xhce5EZCRwGzBLVafiehRdSWifvyfx+vP76et8nY/rblqAu1nq4X7tQVVD+gGcCiz2e30XcFewyzXAx/gqbnCeTUCuNy0X13c46OU7guPJ8/545wOvAYLr7B7V2zkNpQduzI5ivOsfftPD5dx13x6fgeu19BpwXqifPyAfKDrU+QL+G7iqt+UO9gj5Gi1hPi6CiOQDM4GPgRxV3eXN2g3kBKtcR+k/gDsAn/c6E6hV1U7vdSifw7G4m27+x2saeUxEEgmTc6eqZcCDuJuNdgF1wErC5/x16+t8HVHehEPQhi0RSQJeAv5JVev956n7OA25LiMiciGwV1VXBrssARIFnAg8rKozgSZ6NBOE6rkD8NoqL8Z9oIwAEjnwa3dYGYjzFQ5B269xEUKNiETjQvYZVX3Zm7xHRHK9+bnA3mCV7yjMBb4qIttxQ2fOx7VppolI9w00oXwOS4FSVf3Ye70QF7zhcO4AzgaKVbVCVTuAl3HnNFzOX7e+ztcR5U04BO2+MRW8K51X4sZKCFkiIsDjwAZV/Xe/WYuA67zn1+HabkOKqt6lqnmqmo87V/9Q1WuAJcDXvcVC8tgAVHU3UCIi3QORnIW7lTzkz51nJzBHRBK8v9Pu4wuL8+enr/O1CPiW1/tgDlDn18TQt2A3Qg9QQ/YFwOfAVuBnwS7PABzP6bivKmuAVd7jAlxb5t+BzcA7QEawy3qUxzkPeM17Pg43cNAW4EUgNtjlO4rjmgGs8M7fK0B6OJ074D5gI1AEPA3EhvL5A57DtTd34L6R3NDX+cJduH3Iy5q1uN4Xh9yH3RlmjDEBFg5NB8YYM6hZ0BpjTIBZ0BpjTIBZ0BpjTIBZ0BpjTIBZ0JpBS0QavX/zRaTn780d7bb/ucfrDwdy+8b4s6A1oSCfA3/Y86D87lLqy35Bq6qnHWaZjOk3C1oTCh4AviQiq7yxUCNF5F9FZLk3Juj/ByAi80TkPRFZhLtbCRF5RURWeuOn3uxNewCI97b3jDetu/Ys3raLRGStiFzht+1Cv3Fmn/HujEJEHhA3dvAaEXnwmL87ZtAL6I8zGjNA7gR+rKoXAniBWaeqJ4tILPCBiLzlLXsiMFVVi73X31bVahGJB5aLyEuqeqeI3KqqM3rZ12W4O7umA1neOku9eTOB44Fy4ANgrohsAC4FJqmqikjawB66CQdWozWh6Fzc/earcMNHZuIGYgb4xC9kAW4TkdXAR7jBQAo4uNOB51S1S1X3AO8CJ/ttu1RVfbjbovNxwwS2Ao+LyGVA81EemwlDFrQmFAnwfVWd4T3Gqmp3jbZp30Ii83CjTZ2qqtOBz4C4o9hvm9/zLtxA153AKbhRui4E3jyK7ZswZUFrQkEDkOz3ejHwXW8oSURkgje4dk+pQI2qNovIJNzPAnXr6F6/h/eAK7x24GzgDNxgKb3yxgxOVdXXgdtxTQ7G7MfaaE0oWAN0eU0AT+LGr80HPvUuSFUAl/Sy3pvAd7x21E245oNujwBrRORTdcM0dvtf3E+xrMaNoHaHqu72gro3ycCrIhKHq2n/8IiO0IQ1G73LGGMCzJoOjDEmwCxojTEmwCxojTEmwCxojTEmwCxojTEmwCxojTEmwCxojTEmwCxojTEmwP5/8Dk61atxxyUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 360x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#評価指標の差\n",
    "y_va1_pred_proba = model.predict_proba(x_va1)\n",
    "y_va2_pred_proba = model.predict_proba(x_va2)\n",
    "y_va1_pred = model.predict(x_va1)\n",
    "y_va2_pred = model.predict(x_va2)\n",
    "\n",
    "print('[検証データ] auc: {:.4f}'.format(roc_auc_score(y_va1, y_va1_pred_proba[:,1])))\n",
    "print('[ベースライン検証データ] auc: {:.4f}'.format(roc_auc_score(y_va2, y_va2_pred_proba[:,1])))\n",
    "\n",
    "ax = lgb.plot_metric(model.evals_result_, metric='auc', figsize=(5, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b803283a-5082-4103-acc9-73e978db051d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "検証データ\n",
      "[[7451   58]\n",
      " [ 535  174]]\n",
      "[[0.90666829 0.00705768]\n",
      " [0.065101   0.02117303]]\n",
      "ベースライン検証データ\n",
      "[[9307   79]\n",
      " [ 655  231]]\n",
      "[[0.9060553  0.00769081]\n",
      " [0.06376558 0.02248832]]\n"
     ]
    }
   ],
   "source": [
    "#誤分類の分布\n",
    "print('検証データ')\n",
    "print(confusion_matrix(y_va1, y_va1_pred))\n",
    "print(confusion_matrix(y_va1, y_va1_pred, normalize='all'))\n",
    "\n",
    "print('ベースライン検証データ')\n",
    "print(confusion_matrix(y_va2, y_va2_pred))\n",
    "print(confusion_matrix(y_va2, y_va2_pred, normalize='all'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ec0908aa-7f91-466d-90a2-328f35ad6b50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0xffff645b9f10>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 予測値の分布\n",
    "y_va1_pred_prob = model.predict_proba(x_va1)[:,1]\n",
    "y_va2_pred_prob = model.predict_proba(x_va2)[:,1]\n",
    "\n",
    "fig = plt.figure(figsize=(10,8))\n",
    "\n",
    "fig.add_subplot(2,1,1)\n",
    "plt.title('validation_data')\n",
    "plt.hist(y_va1_pred_prob[np.array(y_va1).reshape(-1)==1], bins=10, alpha=0.5, label='1')\n",
    "plt.hist(y_va1_pred_prob[np.array(y_va1).reshape(-1)==0], bins=10, alpha=0.5, label='0')\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "\n",
    "fig.add_subplot(2,1,2)\n",
    "plt.title('basreline_validation_data')\n",
    "plt.hist(y_va2_pred_prob[np.array(y_va2).reshape(-1)==1], bins=10, alpha=0.5, label='1')\n",
    "plt.hist(y_va2_pred_prob[np.array(y_va2).reshape(-1)==0], bins=10, alpha=0.5, label='0')\n",
    "plt.grid()\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baa73b02-6b87-49d4-b5fb-99c28bae0558",
   "metadata": {},
   "source": [
    "## チューニング"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "3de9f10e-747b-479b-ab64-efa6dc7a8182",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "70db80db-fdca-45a7-93c4-bc3a9f98d36d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 探索するパラメータ\n",
    "\n",
    "params_base = {\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'binary',\n",
    "    'metrics': 'auc',\n",
    "    'learning_rate': 0.02,\n",
    "    'n_estimators': 100000,\n",
    "    'bagging_freq': 1,\n",
    "    'seed': 123,\n",
    "}\n",
    "random_state=123\n",
    "\n",
    "def objective(trial):\n",
    "    # 探索するパラメータ\n",
    "    params_tuning = {\n",
    "        'num_leaves': trial.suggest_int('num_leaves',8,256),\n",
    "        'min_data_in_leaf': trial.suggest_int('min_data_in_leaf',5,200),\n",
    "        'min_sum_hessian_in_leaf': trial.suggest_float('min_sum_hessian_in_leaf', 1e-5, 1e-2, log=True),\n",
    "        'feature_fraction': trial.suggest_float('feature_fraction', 0.5, 1.0),\n",
    "        'bagging_fraction': trial.suggest_float('bagging_fraction', 0.5, 1.0),\n",
    "        'reg_alpha': trial.suggest_float('reg_alpha', 1e-2, 1e2, log=True),\n",
    "        'reg_lambda': trial.suggest_float('reg_lambda', 1e-2, 1e2, log=True),\n",
    "    }\n",
    "    params_tuning.update(params_base)\n",
    "    \n",
    "    # モデル学習・評価\n",
    "    list_metrics = []\n",
    "    cv = list(StratifiedKFold(n_splits=4, shuffle=True, random_state=random_state).split(n_train, y_train))\n",
    "    for nfold in np.arange(4):\n",
    "        idx_tr, idx_va = cv[nfold][0], cv[nfold][1]\n",
    "        x_tr, y_tr = n_train.loc[idx_tr, :], y_train.loc[idx_tr, :]\n",
    "        x_va, y_va = n_train.loc[idx_va, :], y_train.loc[idx_va, :]\n",
    "        cat_cols = ['facility_id', 'icu_id']\n",
    "        x_tr, x_va = target_encoding(cat_cols, x_tr, y_tr, x_va)\n",
    "    \n",
    "        model = lgb.LGBMClassifier(**params_tuning)\n",
    "        model.fit(x_tr,\n",
    "                  y_tr,\n",
    "                  eval_set=[(x_tr, y_tr), (x_va, y_va)],\n",
    "                  early_stopping_rounds=100,\n",
    "                  verbose=0,\n",
    "                 )\n",
    "        y_va_pred = model.predict_proba(x_va)[:,1]\n",
    "        metric_va = accuracy_score(y_va, np.where(y_va_pred>0.5, 1, 0))\n",
    "        list_metrics.append(metric_va)\n",
    "        \n",
    "    # 評価値の計算\n",
    "    metrics = np.mean(list_metrics)\n",
    "    \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a3f29f31-8804-444a-8707-ec8f6da339ad",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-03-26 17:02:05,054]\u001b[0m A new study created in memory with name: no-name-6a4964f3-693a-4e1d-be5a-e3f9c6ba7d9d\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_fraction is set=0.8597344848927815, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8597344848927815\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=4.792414358623587e-05, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=4.792414358623587e-05\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=61, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=61\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7756573845414456, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7756573845414456\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8597344848927815, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8597344848927815\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=4.792414358623587e-05, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=4.792414358623587e-05\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=61, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=61\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7756573845414456, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7756573845414456\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8597344848927815, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8597344848927815\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=4.792414358623587e-05, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=4.792414358623587e-05\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=61, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=61\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7756573845414456, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7756573845414456\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8597344848927815, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8597344848927815\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=4.792414358623587e-05, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=4.792414358623587e-05\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=61, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=61\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7756573845414456, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7756573845414456\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-03-26 17:02:34,357]\u001b[0m Trial 0 finished with value: 0.9292042471718399 and parameters: {'num_leaves': 181, 'min_data_in_leaf': 61, 'min_sum_hessian_in_leaf': 4.792414358623587e-05, 'feature_fraction': 0.7756573845414456, 'bagging_fraction': 0.8597344848927815, 'reg_alpha': 0.492522233779106, 'reg_lambda': 83.76388146302445}. Best is trial 0 with value: 0.9292042471718399.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_fraction is set=0.8645248536920208, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8645248536920208\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.00015009027543233888, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.00015009027543233888\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=99, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=99\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6715890080754348, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6715890080754348\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8645248536920208, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8645248536920208\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.00015009027543233888, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.00015009027543233888\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=99, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=99\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6715890080754348, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6715890080754348\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8645248536920208, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8645248536920208\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.00015009027543233888, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.00015009027543233888\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=99, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=99\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6715890080754348, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6715890080754348\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8645248536920208, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8645248536920208\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.00015009027543233888, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.00015009027543233888\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=99, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=99\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6715890080754348, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6715890080754348\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-03-26 17:02:53,020]\u001b[0m Trial 1 finished with value: 0.9297883593213726 and parameters: {'num_leaves': 178, 'min_data_in_leaf': 99, 'min_sum_hessian_in_leaf': 0.00015009027543233888, 'feature_fraction': 0.6715890080754348, 'bagging_fraction': 0.8645248536920208, 'reg_alpha': 0.567922374174008, 'reg_lambda': 0.01732652966363563}. Best is trial 1 with value: 0.9297883593213726.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_fraction is set=0.7657756869209191, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7657756869209191\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=3.52756635172055e-05, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=3.52756635172055e-05\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=149, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=149\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5877258780737462, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5877258780737462\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7657756869209191, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7657756869209191\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=3.52756635172055e-05, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=3.52756635172055e-05\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=149, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=149\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5877258780737462, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5877258780737462\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7657756869209191, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7657756869209191\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=3.52756635172055e-05, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=3.52756635172055e-05\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=149, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=149\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5877258780737462, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5877258780737462\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7657756869209191, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7657756869209191\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=3.52756635172055e-05, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=3.52756635172055e-05\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=149, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=149\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5877258780737462, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5877258780737462\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-03-26 17:03:07,178]\u001b[0m Trial 2 finished with value: 0.9296131196104935 and parameters: {'num_leaves': 107, 'min_data_in_leaf': 149, 'min_sum_hessian_in_leaf': 3.52756635172055e-05, 'feature_fraction': 0.5877258780737462, 'bagging_fraction': 0.7657756869209191, 'reg_alpha': 1.3406343673102123, 'reg_lambda': 3.4482904089131434}. Best is trial 1 with value: 0.9297883593213726.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_fraction is set=0.6614794569265892, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6614794569265892\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0006808799287054756, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0006808799287054756\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=146, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=146\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8612216912851107, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8612216912851107\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6614794569265892, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6614794569265892\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0006808799287054756, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0006808799287054756\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=146, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=146\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8612216912851107, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8612216912851107\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6614794569265892, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6614794569265892\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0006808799287054756, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0006808799287054756\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=146, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=146\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8612216912851107, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8612216912851107\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6614794569265892, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6614794569265892\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0006808799287054756, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0006808799287054756\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=146, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=146\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8612216912851107, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8612216912851107\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-03-26 17:03:20,954]\u001b[0m Trial 3 finished with value: 0.9298857189288187 and parameters: {'num_leaves': 219, 'min_data_in_leaf': 146, 'min_sum_hessian_in_leaf': 0.0006808799287054756, 'feature_fraction': 0.8612216912851107, 'bagging_fraction': 0.6614794569265892, 'reg_alpha': 0.2799978022399009, 'reg_lambda': 0.08185645330667264}. Best is trial 3 with value: 0.9298857189288187.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_fraction is set=0.7154313816648219, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7154313816648219\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=1.889360449174926e-05, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=1.889360449174926e-05\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=128, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=128\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7168505863397641, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7168505863397641\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7154313816648219, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7154313816648219\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=1.889360449174926e-05, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=1.889360449174926e-05\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=128, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=128\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7168505863397641, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7168505863397641\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7154313816648219, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7154313816648219\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=1.889360449174926e-05, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=1.889360449174926e-05\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=128, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=128\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7168505863397641, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7168505863397641\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7154313816648219, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7154313816648219\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=1.889360449174926e-05, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=1.889360449174926e-05\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=128, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=128\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7168505863397641, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7168505863397641\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-03-26 17:03:33,151]\u001b[0m Trial 4 finished with value: 0.9298078266933474 and parameters: {'num_leaves': 81, 'min_data_in_leaf': 128, 'min_sum_hessian_in_leaf': 1.889360449174926e-05, 'feature_fraction': 0.7168505863397641, 'bagging_fraction': 0.7154313816648219, 'reg_alpha': 0.9434967110751797, 'reg_lambda': 0.5050346330980694}. Best is trial 3 with value: 0.9298857189288187.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_fraction is set=0.7509183379421682, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7509183379421682\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.004788147156768277, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.004788147156768277\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=88, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=88\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9720800091019398, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9720800091019398\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7509183379421682, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7509183379421682\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.004788147156768277, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.004788147156768277\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=88, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=88\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9720800091019398, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9720800091019398\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7509183379421682, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7509183379421682\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.004788147156768277, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.004788147156768277\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=88, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=88\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9720800091019398, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9720800091019398\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7509183379421682, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7509183379421682\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.004788147156768277, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.004788147156768277\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=88, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=88\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9720800091019398, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9720800091019398\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-03-26 17:03:46,123]\u001b[0m Trial 5 finished with value: 0.9299051787182695 and parameters: {'num_leaves': 85, 'min_data_in_leaf': 88, 'min_sum_hessian_in_leaf': 0.004788147156768277, 'feature_fraction': 0.9720800091019398, 'bagging_fraction': 0.7509183379421682, 'reg_alpha': 3.1319282717196035, 'reg_lambda': 0.029005047452739414}. Best is trial 5 with value: 0.9299051787182695.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_fraction is set=0.7415171321313522, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7415171321313522\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.003971252247766701, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.003971252247766701\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=86, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=86\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6252276826982534, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6252276826982534\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7415171321313522, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7415171321313522\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.003971252247766701, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.003971252247766701\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=86, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=86\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6252276826982534, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6252276826982534\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7415171321313522, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7415171321313522\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.003971252247766701, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.003971252247766701\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=86, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=86\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6252276826982534, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6252276826982534\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7415171321313522, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7415171321313522\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.003971252247766701, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.003971252247766701\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=86, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=86\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6252276826982534, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6252276826982534\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-03-26 17:04:38,671]\u001b[0m Trial 6 finished with value: 0.9249401572045259 and parameters: {'num_leaves': 87, 'min_data_in_leaf': 86, 'min_sum_hessian_in_leaf': 0.003971252247766701, 'feature_fraction': 0.6252276826982534, 'bagging_fraction': 0.7415171321313522, 'reg_alpha': 87.54657140659076, 'reg_lambda': 1.1965765212602313}. Best is trial 5 with value: 0.9299051787182695.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_fraction is set=0.7725340032332324, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7725340032332324\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0030131614432849746, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0030131614432849746\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=28, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=28\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8015300642054637, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8015300642054637\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7725340032332324, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7725340032332324\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0030131614432849746, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0030131614432849746\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=28, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=28\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8015300642054637, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8015300642054637\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7725340032332324, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7725340032332324\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0030131614432849746, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0030131614432849746\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=28, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=28\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8015300642054637, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8015300642054637\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7725340032332324, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7725340032332324\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0030131614432849746, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0030131614432849746\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=28, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=28\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8015300642054637, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8015300642054637\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-03-26 17:05:06,028]\u001b[0m Trial 7 finished with value: 0.9303724911854675 and parameters: {'num_leaves': 160, 'min_data_in_leaf': 28, 'min_sum_hessian_in_leaf': 0.0030131614432849746, 'feature_fraction': 0.8015300642054637, 'bagging_fraction': 0.7725340032332324, 'reg_alpha': 0.23499322154972468, 'reg_lambda': 0.1646202117975735}. Best is trial 7 with value: 0.9303724911854675.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_fraction is set=0.8346568914811361, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8346568914811361\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.00423029374725911, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.00423029374725911\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=138, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=138\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7552111687390055, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7552111687390055\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8346568914811361, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8346568914811361\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.00423029374725911, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.00423029374725911\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=138, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=138\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7552111687390055, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7552111687390055\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8346568914811361, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8346568914811361\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.00423029374725911, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.00423029374725911\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=138, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=138\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7552111687390055, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7552111687390055\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8346568914811361, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8346568914811361\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.00423029374725911, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.00423029374725911\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=138, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=138\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7552111687390055, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7552111687390055\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-03-26 17:05:24,450]\u001b[0m Trial 8 finished with value: 0.9299441255942575 and parameters: {'num_leaves': 111, 'min_data_in_leaf': 138, 'min_sum_hessian_in_leaf': 0.00423029374725911, 'feature_fraction': 0.7552111687390055, 'bagging_fraction': 0.8346568914811361, 'reg_alpha': 2.206714812711709, 'reg_lambda': 3.1594683442464033}. Best is trial 7 with value: 0.9303724911854675.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_fraction is set=0.6218331872684371, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6218331872684371\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=1.7765808030254076e-05, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=1.7765808030254076e-05\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=170, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=170\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8818414207216692, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8818414207216692\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6218331872684371, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6218331872684371\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=1.7765808030254076e-05, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=1.7765808030254076e-05\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=170, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=170\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8818414207216692, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8818414207216692\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6218331872684371, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6218331872684371\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=1.7765808030254076e-05, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=1.7765808030254076e-05\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=170, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=170\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8818414207216692, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8818414207216692\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6218331872684371, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6218331872684371\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=1.7765808030254076e-05, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=1.7765808030254076e-05\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=170, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=170\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8818414207216692, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8818414207216692\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-03-26 17:05:38,297]\u001b[0m Trial 9 finished with value: 0.9296910133624697 and parameters: {'num_leaves': 175, 'min_data_in_leaf': 170, 'min_sum_hessian_in_leaf': 1.7765808030254076e-05, 'feature_fraction': 0.8818414207216692, 'bagging_fraction': 0.6218331872684371, 'reg_alpha': 0.05982625838323253, 'reg_lambda': 1.9490717640641542}. Best is trial 7 with value: 0.9303724911854675.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_fraction is set=0.9940542446575642, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9940542446575642\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0010167214653943027, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0010167214653943027\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5040305717020102, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5040305717020102\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9940542446575642, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9940542446575642\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0010167214653943027, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0010167214653943027\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5040305717020102, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5040305717020102\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9940542446575642, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9940542446575642\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0010167214653943027, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0010167214653943027\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5040305717020102, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5040305717020102\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9940542446575642, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9940542446575642\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0010167214653943027, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0010167214653943027\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5040305717020102, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5040305717020102\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-03-26 17:05:54,892]\u001b[0m Trial 10 finished with value: 0.9299635808341942 and parameters: {'num_leaves': 32, 'min_data_in_leaf': 6, 'min_sum_hessian_in_leaf': 0.0010167214653943027, 'feature_fraction': 0.5040305717020102, 'bagging_fraction': 0.9940542446575642, 'reg_alpha': 0.010612397212799423, 'reg_lambda': 0.1661409929489422}. Best is trial 7 with value: 0.9303724911854675.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_fraction is set=0.9816139361200471, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9816139361200471\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.000991454198994495, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.000991454198994495\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=7, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=7\n",
      "[LightGBM] [Warning] feature_fraction is set=0.552457608315914, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.552457608315914\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9816139361200471, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9816139361200471\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.000991454198994495, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.000991454198994495\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=7, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=7\n",
      "[LightGBM] [Warning] feature_fraction is set=0.552457608315914, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.552457608315914\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9816139361200471, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9816139361200471\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.000991454198994495, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.000991454198994495\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=7, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=7\n",
      "[LightGBM] [Warning] feature_fraction is set=0.552457608315914, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.552457608315914\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9816139361200471, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9816139361200471\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.000991454198994495, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.000991454198994495\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=7, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=7\n",
      "[LightGBM] [Warning] feature_fraction is set=0.552457608315914, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.552457608315914\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-03-26 17:06:10,701]\u001b[0m Trial 11 finished with value: 0.9300998933836474 and parameters: {'num_leaves': 57, 'min_data_in_leaf': 7, 'min_sum_hessian_in_leaf': 0.000991454198994495, 'feature_fraction': 0.552457608315914, 'bagging_fraction': 0.9816139361200471, 'reg_alpha': 0.011325252532212334, 'reg_lambda': 0.11400599767507363}. Best is trial 7 with value: 0.9303724911854675.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_fraction is set=0.5595408581248553, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5595408581248553\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0011772429116239105, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0011772429116239105\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=16, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=16\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5082312939353781, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5082312939353781\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5595408581248553, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5595408581248553\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0011772429116239105, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0011772429116239105\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=16, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=16\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5082312939353781, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5082312939353781\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5595408581248553, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5595408581248553\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0011772429116239105, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0011772429116239105\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=16, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=16\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5082312939353781, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5082312939353781\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5595408581248553, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5595408581248553\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0011772429116239105, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0011772429116239105\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=16, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=16\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5082312939353781, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5082312939353781\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-03-26 17:06:33,992]\u001b[0m Trial 12 finished with value: 0.9302751270285072 and parameters: {'num_leaves': 10, 'min_data_in_leaf': 16, 'min_sum_hessian_in_leaf': 0.0011772429116239105, 'feature_fraction': 0.5082312939353781, 'bagging_fraction': 0.5595408581248553, 'reg_alpha': 0.01159602699379102, 'reg_lambda': 0.01036230661502322}. Best is trial 7 with value: 0.9303724911854675.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_fraction is set=0.5011737451921937, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5011737451921937\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.00964425200568059, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.00964425200568059\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=43, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5018388179694604, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5018388179694604\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5011737451921937, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5011737451921937\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.00964425200568059, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.00964425200568059\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=43, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5018388179694604, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5018388179694604\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5011737451921937, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5011737451921937\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.00964425200568059, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.00964425200568059\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=43, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5018388179694604, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5018388179694604\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5011737451921937, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5011737451921937\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.00964425200568059, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.00964425200568059\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=43, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5018388179694604, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5018388179694604\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-03-26 17:06:51,973]\u001b[0m Trial 13 finished with value: 0.9302167355281161 and parameters: {'num_leaves': 8, 'min_data_in_leaf': 43, 'min_sum_hessian_in_leaf': 0.00964425200568059, 'feature_fraction': 0.5018388179694604, 'bagging_fraction': 0.5011737451921937, 'reg_alpha': 0.049404029796241616, 'reg_lambda': 0.010741655892621712}. Best is trial 7 with value: 0.9303724911854675.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_fraction is set=0.5702475504683538, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5702475504683538\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0017038597330333353, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0017038597330333353\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=35, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=35\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6396458301362229, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6396458301362229\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5702475504683538, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5702475504683538\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0017038597330333353, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0017038597330333353\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=35, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=35\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6396458301362229, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6396458301362229\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5702475504683538, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5702475504683538\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0017038597330333353, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0017038597330333353\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=35, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=35\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6396458301362229, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6396458301362229\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5702475504683538, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5702475504683538\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0017038597330333353, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0017038597330333353\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=35, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=35\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6396458301362229, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6396458301362229\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-03-26 17:07:12,513]\u001b[0m Trial 14 finished with value: 0.9300414943007324 and parameters: {'num_leaves': 252, 'min_data_in_leaf': 35, 'min_sum_hessian_in_leaf': 0.0017038597330333353, 'feature_fraction': 0.6396458301362229, 'bagging_fraction': 0.5702475504683538, 'reg_alpha': 0.06618100230922958, 'reg_lambda': 0.02945708758420021}. Best is trial 7 with value: 0.9303724911854675.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_fraction is set=0.5024707401359401, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5024707401359401\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.00033040787452620027, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.00033040787452620027\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=35, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=35\n",
      "[LightGBM] [Warning] feature_fraction is set=0.690460596426745, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.690460596426745\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5024707401359401, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5024707401359401\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.00033040787452620027, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.00033040787452620027\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=35, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=35\n",
      "[LightGBM] [Warning] feature_fraction is set=0.690460596426745, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.690460596426745\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5024707401359401, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5024707401359401\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.00033040787452620027, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.00033040787452620027\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=35, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=35\n",
      "[LightGBM] [Warning] feature_fraction is set=0.690460596426745, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.690460596426745\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5024707401359401, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5024707401359401\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.00033040787452620027, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.00033040787452620027\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=35, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=35\n",
      "[LightGBM] [Warning] feature_fraction is set=0.690460596426745, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.690460596426745\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-03-26 17:07:27,847]\u001b[0m Trial 15 finished with value: 0.9290484642174022 and parameters: {'num_leaves': 142, 'min_data_in_leaf': 35, 'min_sum_hessian_in_leaf': 0.00033040787452620027, 'feature_fraction': 0.690460596426745, 'bagging_fraction': 0.5024707401359401, 'reg_alpha': 0.13370881018814096, 'reg_lambda': 0.043977290456925416}. Best is trial 7 with value: 0.9303724911854675.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_fraction is set=0.6452398944350926, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6452398944350926\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0021159525252302494, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0021159525252302494\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=65, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=65\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7970553508142445, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7970553508142445\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6452398944350926, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6452398944350926\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0021159525252302494, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0021159525252302494\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=65, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=65\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7970553508142445, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7970553508142445\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6452398944350926, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6452398944350926\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0021159525252302494, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0021159525252302494\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=65, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=65\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7970553508142445, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7970553508142445\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6452398944350926, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6452398944350926\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0021159525252302494, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0021159525252302494\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=65, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=65\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7970553508142445, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7970553508142445\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-03-26 17:07:41,885]\u001b[0m Trial 16 finished with value: 0.9299246673213115 and parameters: {'num_leaves': 148, 'min_data_in_leaf': 65, 'min_sum_hessian_in_leaf': 0.0021159525252302494, 'feature_fraction': 0.7970553508142445, 'bagging_fraction': 0.6452398944350926, 'reg_alpha': 0.019334078224433136, 'reg_lambda': 0.01033528363848504}. Best is trial 7 with value: 0.9303724911854675.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_fraction is set=0.5752171935407671, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5752171935407671\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.00041942600526778174, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.00041942600526778174\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=23, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=23\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5869412794303933, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5869412794303933\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5752171935407671, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5752171935407671\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.00041942600526778174, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.00041942600526778174\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=23, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=23\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5869412794303933, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5869412794303933\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5752171935407671, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5752171935407671\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.00041942600526778174, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.00041942600526778174\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=23, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=23\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5869412794303933, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5869412794303933\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5752171935407671, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5752171935407671\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.00041942600526778174, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.00041942600526778174\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=23, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=23\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5869412794303933, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5869412794303933\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-03-26 17:08:02,806]\u001b[0m Trial 17 finished with value: 0.9297883669038965 and parameters: {'num_leaves': 218, 'min_data_in_leaf': 23, 'min_sum_hessian_in_leaf': 0.00041942600526778174, 'feature_fraction': 0.5869412794303933, 'bagging_fraction': 0.5752171935407671, 'reg_alpha': 0.025311724004931247, 'reg_lambda': 0.33628795681597595}. Best is trial 7 with value: 0.9303724911854675.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_fraction is set=0.693885320471026, subsample=1.0 will be ignored. Current value: bagging_fraction=0.693885320471026\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.00017334697738671855, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.00017334697738671855\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=192, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=192\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7170673281924885, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7170673281924885\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.693885320471026, subsample=1.0 will be ignored. Current value: bagging_fraction=0.693885320471026\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.00017334697738671855, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.00017334697738671855\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=192, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=192\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7170673281924885, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7170673281924885\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.693885320471026, subsample=1.0 will be ignored. Current value: bagging_fraction=0.693885320471026\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.00017334697738671855, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.00017334697738671855\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=192, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=192\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7170673281924885, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7170673281924885\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.693885320471026, subsample=1.0 will be ignored. Current value: bagging_fraction=0.693885320471026\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.00017334697738671855, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.00017334697738671855\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=192, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=192\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7170673281924885, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7170673281924885\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-03-26 17:08:14,271]\u001b[0m Trial 18 finished with value: 0.9305282635243717 and parameters: {'num_leaves': 46, 'min_data_in_leaf': 192, 'min_sum_hessian_in_leaf': 0.00017334697738671855, 'feature_fraction': 0.7170673281924885, 'bagging_fraction': 0.693885320471026, 'reg_alpha': 0.1772628567955448, 'reg_lambda': 0.05472030768993216}. Best is trial 18 with value: 0.9305282635243717.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_fraction is set=0.6727788490264094, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6727788490264094\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0001512831384976337, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0001512831384976337\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=200, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=200\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7265378117746244, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7265378117746244\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6727788490264094, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6727788490264094\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0001512831384976337, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0001512831384976337\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=200, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=200\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7265378117746244, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7265378117746244\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6727788490264094, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6727788490264094\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0001512831384976337, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0001512831384976337\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=200, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=200\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7265378117746244, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7265378117746244\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6727788490264094, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6727788490264094\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0001512831384976337, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0001512831384976337\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=200, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=200\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7265378117746244, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7265378117746244\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-03-26 17:08:27,904]\u001b[0m Trial 19 finished with value: 0.9293210635357272 and parameters: {'num_leaves': 49, 'min_data_in_leaf': 200, 'min_sum_hessian_in_leaf': 0.0001512831384976337, 'feature_fraction': 0.7265378117746244, 'bagging_fraction': 0.6727788490264094, 'reg_alpha': 0.1901921923183269, 'reg_lambda': 0.05322539089196862}. Best is trial 18 with value: 0.9305282635243717.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_fraction is set=0.7938749424483875, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7938749424483875\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0001745939889031575, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0001745939889031575\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=194, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=194\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8021429800461279, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8021429800461279\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7938749424483875, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7938749424483875\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0001745939889031575, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0001745939889031575\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=194, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=194\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8021429800461279, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8021429800461279\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7938749424483875, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7938749424483875\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0001745939889031575, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0001745939889031575\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=194, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=194\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8021429800461279, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8021429800461279\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7938749424483875, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7938749424483875\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0001745939889031575, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0001745939889031575\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=194, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=194\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8021429800461279, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8021429800461279\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-03-26 17:08:43,915]\u001b[0m Trial 20 finished with value: 0.9298857219618283 and parameters: {'num_leaves': 158, 'min_data_in_leaf': 194, 'min_sum_hessian_in_leaf': 0.0001745939889031575, 'feature_fraction': 0.8021429800461279, 'bagging_fraction': 0.7938749424483875, 'reg_alpha': 0.15470937382525465, 'reg_lambda': 0.20155916582751363}. Best is trial 18 with value: 0.9305282635243717.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_fraction is set=0.6940449441275507, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6940449441275507\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0006336965286253373, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0006336965286253373\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=63, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=63\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6763043207576405, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6763043207576405\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6940449441275507, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6940449441275507\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0006336965286253373, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0006336965286253373\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=63, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=63\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6763043207576405, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6763043207576405\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6940449441275507, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6940449441275507\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0006336965286253373, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0006336965286253373\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=63, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=63\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6763043207576405, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6763043207576405\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6940449441275507, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6940449441275507\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0006336965286253373, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0006336965286253373\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=63, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=63\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6763043207576405, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6763043207576405\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-03-26 17:09:01,071]\u001b[0m Trial 21 finished with value: 0.9295936522385186 and parameters: {'num_leaves': 8, 'min_data_in_leaf': 63, 'min_sum_hessian_in_leaf': 0.0006336965286253373, 'feature_fraction': 0.6763043207576405, 'bagging_fraction': 0.6940449441275507, 'reg_alpha': 0.03842488453148413, 'reg_lambda': 0.058564740968220945}. Best is trial 18 with value: 0.9305282635243717.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_fraction is set=0.7045329194506366, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7045329194506366\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.001830751538863638, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.001830751538863638\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=21, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=21\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7259183848653861, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7259183848653861\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7045329194506366, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7045329194506366\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.001830751538863638, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.001830751538863638\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=21, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=21\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7259183848653861, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7259183848653861\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7045329194506366, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7045329194506366\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.001830751538863638, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.001830751538863638\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=21, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=21\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7259183848653861, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7259183848653861\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7045329194506366, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7045329194506366\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.001830751538863638, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.001830751538863638\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=21, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=21\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7259183848653861, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7259183848653861\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-03-26 17:09:14,537]\u001b[0m Trial 22 finished with value: 0.9299246521562635 and parameters: {'num_leaves': 39, 'min_data_in_leaf': 21, 'min_sum_hessian_in_leaf': 0.001830751538863638, 'feature_fraction': 0.7259183848653861, 'bagging_fraction': 0.7045329194506366, 'reg_alpha': 0.11311814251672293, 'reg_lambda': 0.022441717547825354}. Best is trial 18 with value: 0.9305282635243717.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_fraction is set=0.6169712716037121, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6169712716037121\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0003247960568681629, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0003247960568681629\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=113, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=113\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6460527266501457, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6460527266501457\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6169712716037121, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6169712716037121\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0003247960568681629, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0003247960568681629\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=113, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=113\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6460527266501457, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6460527266501457\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6169712716037121, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6169712716037121\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0003247960568681629, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0003247960568681629\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=113, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=113\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6460527266501457, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6460527266501457\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6169712716037121, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6169712716037121\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0003247960568681629, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0003247960568681629\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=113, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=113\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6460527266501457, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6460527266501457\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-03-26 17:09:30,134]\u001b[0m Trial 23 finished with value: 0.9306450905037926 and parameters: {'num_leaves': 119, 'min_data_in_leaf': 113, 'min_sum_hessian_in_leaf': 0.0003247960568681629, 'feature_fraction': 0.6460527266501457, 'bagging_fraction': 0.6169712716037121, 'reg_alpha': 0.028105310658606258, 'reg_lambda': 0.10619688398329478}. Best is trial 23 with value: 0.9306450905037926.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_fraction is set=0.623545387976872, subsample=1.0 will be ignored. Current value: bagging_fraction=0.623545387976872\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.00022348870192262981, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.00022348870192262981\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=172, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=172\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6587768585473897, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6587768585473897\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.623545387976872, subsample=1.0 will be ignored. Current value: bagging_fraction=0.623545387976872\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.00022348870192262981, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.00022348870192262981\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=172, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=172\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6587768585473897, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6587768585473897\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.623545387976872, subsample=1.0 will be ignored. Current value: bagging_fraction=0.623545387976872\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.00022348870192262981, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.00022348870192262981\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=172, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=172\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6587768585473897, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6587768585473897\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.623545387976872, subsample=1.0 will be ignored. Current value: bagging_fraction=0.623545387976872\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.00022348870192262981, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.00022348870192262981\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=172, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=172\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6587768585473897, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6587768585473897\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-03-26 17:09:43,121]\u001b[0m Trial 24 finished with value: 0.929710491349978 and parameters: {'num_leaves': 120, 'min_data_in_leaf': 172, 'min_sum_hessian_in_leaf': 0.00022348870192262981, 'feature_fraction': 0.6587768585473897, 'bagging_fraction': 0.623545387976872, 'reg_alpha': 0.08719667988379043, 'reg_lambda': 0.09736915167388008}. Best is trial 23 with value: 0.9306450905037926.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_fraction is set=0.706090260541778, subsample=1.0 will be ignored. Current value: bagging_fraction=0.706090260541778\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=9.105799384867685e-05, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=9.105799384867685e-05\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=116, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=116\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7094962388840546, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7094962388840546\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.706090260541778, subsample=1.0 will be ignored. Current value: bagging_fraction=0.706090260541778\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=9.105799384867685e-05, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=9.105799384867685e-05\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=116, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=116\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7094962388840546, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7094962388840546\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.706090260541778, subsample=1.0 will be ignored. Current value: bagging_fraction=0.706090260541778\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=9.105799384867685e-05, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=9.105799384867685e-05\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=116, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=116\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7094962388840546, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7094962388840546\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.706090260541778, subsample=1.0 will be ignored. Current value: bagging_fraction=0.706090260541778\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=9.105799384867685e-05, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=9.105799384867685e-05\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=116, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=116\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7094962388840546, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7094962388840546\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-03-26 17:09:58,683]\u001b[0m Trial 25 finished with value: 0.9295741863830488 and parameters: {'num_leaves': 199, 'min_data_in_leaf': 116, 'min_sum_hessian_in_leaf': 9.105799384867685e-05, 'feature_fraction': 0.7094962388840546, 'bagging_fraction': 0.706090260541778, 'reg_alpha': 0.31491796599336036, 'reg_lambda': 0.3287048364174787}. Best is trial 23 with value: 0.9306450905037926.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_fraction is set=0.6224015290254946, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6224015290254946\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0004570599250071687, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0004570599250071687\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=168, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=168\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7561269779942515, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7561269779942515\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6224015290254946, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6224015290254946\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0004570599250071687, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0004570599250071687\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=168, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=168\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7561269779942515, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7561269779942515\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6224015290254946, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6224015290254946\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0004570599250071687, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0004570599250071687\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=168, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=168\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7561269779942515, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7561269779942515\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6224015290254946, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6224015290254946\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0004570599250071687, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0004570599250071687\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=168, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=168\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7561269779942515, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7561269779942515\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-03-26 17:10:13,855]\u001b[0m Trial 26 finished with value: 0.9300414882347132 and parameters: {'num_leaves': 127, 'min_data_in_leaf': 168, 'min_sum_hessian_in_leaf': 0.0004570599250071687, 'feature_fraction': 0.7561269779942515, 'bagging_fraction': 0.6224015290254946, 'reg_alpha': 0.030076610853130133, 'reg_lambda': 0.14303725244157842}. Best is trial 23 with value: 0.9306450905037926.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_fraction is set=0.7749517883796162, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7749517883796162\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.00030279503155269586, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.00030279503155269586\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=111, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=111\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6249312811581513, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6249312811581513\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7749517883796162, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7749517883796162\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.00030279503155269586, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.00030279503155269586\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=111, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=111\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6249312811581513, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6249312811581513\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7749517883796162, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7749517883796162\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.00030279503155269586, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.00030279503155269586\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=111, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=111\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6249312811581513, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6249312811581513\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7749517883796162, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7749517883796162\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.00030279503155269586, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.00030279503155269586\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=111, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=111\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6249312811581513, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6249312811581513\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-03-26 17:10:27,786]\u001b[0m Trial 27 finished with value: 0.9306450783717544 and parameters: {'num_leaves': 63, 'min_data_in_leaf': 111, 'min_sum_hessian_in_leaf': 0.00030279503155269586, 'feature_fraction': 0.6249312811581513, 'bagging_fraction': 0.7749517883796162, 'reg_alpha': 0.0696257604575403, 'reg_lambda': 0.05649986721895862}. Best is trial 23 with value: 0.9306450905037926.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_fraction is set=0.6746005577540128, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6746005577540128\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0002836428386674045, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0002836428386674045\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=115, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=115\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6245784772581751, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6245784772581751\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6746005577540128, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6746005577540128\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0002836428386674045, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0002836428386674045\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=115, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=115\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6245784772581751, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6245784772581751\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6746005577540128, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6746005577540128\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0002836428386674045, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0002836428386674045\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=115, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=115\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6245784772581751, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6245784772581751\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6746005577540128, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6746005577540128\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0002836428386674045, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0002836428386674045\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=115, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=115\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6245784772581751, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6245784772581751\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-03-26 17:10:42,724]\u001b[0m Trial 28 finished with value: 0.9300609586396976 and parameters: {'num_leaves': 71, 'min_data_in_leaf': 115, 'min_sum_hessian_in_leaf': 0.0002836428386674045, 'feature_fraction': 0.6245784772581751, 'bagging_fraction': 0.6746005577540128, 'reg_alpha': 0.07446361968017055, 'reg_lambda': 0.0461531952556658}. Best is trial 23 with value: 0.9306450905037926.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_fraction is set=0.7233344932111209, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7233344932111209\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=6.839185136974349e-05, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=6.839185136974349e-05\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=186, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=186\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6408046006113458, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6408046006113458\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7233344932111209, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7233344932111209\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=6.839185136974349e-05, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=6.839185136974349e-05\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=186, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=186\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6408046006113458, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6408046006113458\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7233344932111209, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7233344932111209\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=6.839185136974349e-05, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=6.839185136974349e-05\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=186, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=186\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6408046006113458, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6408046006113458\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7233344932111209, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7233344932111209\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=6.839185136974349e-05, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=6.839185136974349e-05\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=186, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=186\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6408046006113458, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6408046006113458\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-03-26 17:10:55,914]\u001b[0m Trial 29 finished with value: 0.9301193789536797 and parameters: {'num_leaves': 65, 'min_data_in_leaf': 186, 'min_sum_hessian_in_leaf': 6.839185136974349e-05, 'feature_fraction': 0.6408046006113458, 'bagging_fraction': 0.7233344932111209, 'reg_alpha': 0.02530221552624873, 'reg_lambda': 0.07285277672848327}. Best is trial 23 with value: 0.9306450905037926.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "sampler = optuna.samplers.TPESampler(seed=random_state)\n",
    "study = optuna.create_study(sampler=sampler, direction='maximize')\n",
    "study.optimize(objective, n_trials=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "742e8090-a6cc-4b48-8846-a2bc76544529",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc(best)=0.9306\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'num_leaves': 119,\n",
       " 'min_data_in_leaf': 113,\n",
       " 'min_sum_hessian_in_leaf': 0.0003247960568681629,\n",
       " 'feature_fraction': 0.6460527266501457,\n",
       " 'bagging_fraction': 0.6169712716037121,\n",
       " 'reg_alpha': 0.028105310658606258,\n",
       " 'reg_lambda': 0.10619688398329478}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trial = study.best_trial\n",
    "print('acc(best)={:.4f}'.format(trial.value))\n",
    "display(trial.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ca44ab14-da64-4d5a-b1bb-fb87183712b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'num_leaves': 119,\n",
       " 'min_data_in_leaf': 113,\n",
       " 'min_sum_hessian_in_leaf': 0.0003247960568681629,\n",
       " 'feature_fraction': 0.6460527266501457,\n",
       " 'bagging_fraction': 0.6169712716037121,\n",
       " 'reg_alpha': 0.028105310658606258,\n",
       " 'reg_lambda': 0.10619688398329478,\n",
       " 'boosting_type': 'gbdt',\n",
       " 'objective': 'binary',\n",
       " 'metrics': 'auc',\n",
       " 'learning_rate': 0.02,\n",
       " 'n_estimators': 100000,\n",
       " 'bagging_freq': 1,\n",
       " 'seed': 123}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "params_best = trial.params\n",
    "params_best.update(params_base)\n",
    "display(params_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c94ccfa-aedc-45f7-b332-22367698712d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e81d0070-66b7-4e08-bb4d-f2969a4d40d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "5c81de3d-741d-444d-bda7-3a4bcd6bbe34",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7ff10c663d00>"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#　血圧との関係\n",
    "plt.hist(train.loc[train['Outcome'] == 0, 'BloodPressure'].dropna(),\n",
    "         bins=30, alpha=0.5, label='0')\n",
    "plt.hist(train.loc[train['Outcome'] == 1, 'BloodPressure'].dropna(),\n",
    "         bins=30, alpha=0.5, label='1')\n",
    "plt.xlabel('BloodPressure')\n",
    "plt.ylabel('count')\n",
    "plt.legend(title='Outcome')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "02f43917-1d72-4991-b757-b6de5ce95787",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3000 entries, 0 to 2999\n",
      "Data columns (total 11 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   index                     3000 non-null   int64  \n",
      " 1   Pregnancies               3000 non-null   int64  \n",
      " 2   Glucose                   3000 non-null   int64  \n",
      " 3   BloodPressure             3000 non-null   int64  \n",
      " 4   SkinThickness             3000 non-null   int64  \n",
      " 5   Insulin                   3000 non-null   int64  \n",
      " 6   BMI                       3000 non-null   float64\n",
      " 7   DiabetesPedigreeFunction  3000 non-null   float64\n",
      " 8   Age                       3000 non-null   int64  \n",
      " 9   Outcome                   3000 non-null   int64  \n",
      " 10  BloodPressure_new         2887 non-null   float64\n",
      "dtypes: float64(3), int64(8)\n",
      "memory usage: 257.9 KB\n",
      "70.97859744990893\n",
      "72.88277858176556\n",
      "71.43436092829927\n",
      "87\n",
      "26\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train['BloodPressure_new'] = train['BloodPressure'].replace([0], np.nan)\n",
    "plt.hist(train.loc[train['Outcome'] == 0, 'BloodPressure_new'].dropna(),\n",
    "         bins=30, alpha=0.5, label='0')\n",
    "plt.hist(train.loc[train['Outcome'] == 1, 'BloodPressure_new'].dropna(),\n",
    "         bins=30, alpha=0.5, label='1')\n",
    "plt.xlabel('BloodPressure_new')\n",
    "plt.ylabel('count')\n",
    "plt.legend(title='Outcome')\n",
    "\n",
    "train.info()\n",
    "BPmean_0= train.loc[train['Outcome'] == 0, 'BloodPressure_new'].mean()\n",
    "print(BPmean_0)\n",
    "BPmean_1= train.loc[train['Outcome'] == 1, 'BloodPressure_new'].mean()\n",
    "print(BPmean_1)\n",
    "BPmean= train['BloodPressure_new'].mean()\n",
    "print(BPmean)\n",
    "\n",
    "print(train[train['Outcome']==0]['BloodPressure_new'].isnull().sum(axis=0))\n",
    "print(train[train['Outcome']==1]['BloodPressure_new'].isnull().sum(axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c627b6f-4a8a-43aa-b965-249b78956e24",
   "metadata": {},
   "source": [
    "血圧0は欠損、欠損かどうかの特徴量作成(0なら1、取得された値があれば1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03a77ca8-f37f-410b-bead-ba0329a55a61",
   "metadata": {},
   "source": [
    "## 欠損処理関数"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7868b15a-33ec-4991-819a-e03fd14c83aa",
   "metadata": {},
   "source": [
    "train = pd.read_csv(\"data/train.csv\")\n",
    "test = pd.read_csv(\"data/test.csv\")\n",
    "sample= pd.read_csv(\"data/sample_submit.csv\",header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "42ab929a-77ad-45b9-bb29-f50ea1bc6d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "#データ読み込み\n",
    "train = pd.read_csv(\"data_EDA/train.csv\")\n",
    "test = pd.read_csv(\"data_EDA/test.csv\")\n",
    "X_train = train[['DiabetesPedigreeFunction',\n",
    "                 'BMI',\n",
    "                 'Glucose',\n",
    "                 'Age',\n",
    "                 'Pregnancies',\n",
    "                 'Pregnancies_bin'\n",
    "                ]]\n",
    "id_train = train[['index']]\n",
    "y_train = train[['Outcome']]\n",
    "\n",
    "\n",
    "X_test = test[X_train.columns]\n",
    "id_test = test[id_train.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "f9456c50-0e72-466d-85c5-662a952f5c0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DiabetesPedigreeFunction\n",
      "BMI\n",
      "Glucose\n",
      "Age\n",
      "Pregnancies\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "# 数値データ\n",
    "col_num = X_train.columns[X_train.dtypes!='object'].values.tolist()\n",
    "\n",
    "dict_num = {}\n",
    "for col in col_num:\n",
    "    print(col)\n",
    "    # 欠損値を0へ\n",
    "    value_fillna = 0 \n",
    "    X_train[col] = X_train[col].fillna(value_fillna)\n",
    "    # 正規化\n",
    "    value_min = X_train[col].min()\n",
    "    value_max = X_train[col].max()\n",
    "    value_mean = X_train[col].mean()\n",
    "    value_std = X_train[col].std()\n",
    "    X_train[col] = (X_train[col] - value_min) / (value_max - value_min)\n",
    "    # X_tarin[col] = (X_train[col] - value_mean) / value_std\n",
    "    \n",
    "    dict_num[col] = {}\n",
    "    dict_num[col]['fillna'] = value_fillna\n",
    "    dict_num[col]['min'] = value_min\n",
    "    dict_num[col]['max'] = value_max\n",
    "    dict_num[col]['mean'] = value_max    \n",
    "    dict_num[col]['std'] = value_max    \n",
    "    \n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "1d2322ac-de5d-4fc3-8e74-f5c1f8caf3e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pregnancies_bin\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "# カテゴリデータ\n",
    "# （embedding予定でラベルエンコーダー）\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "col_cat = X_train.columns[X_train.dtypes=='object'].values.tolist()\n",
    "\n",
    "dict_cat = {}\n",
    "for col in col_cat:\n",
    "    print(col)\n",
    "    value_fillna = 'unknown'\n",
    "    X_train[col] = X_train[col].fillna(value_fillna)\n",
    "    \n",
    "    X_train[col] = X_train[col].astype(str)\n",
    "    # strに変換\n",
    "    le = LabelEncoder()\n",
    "    le.fit(X_train[col])\n",
    "    list_label = sorted(list(set(le.classes_) | set(['unknown'])))\n",
    "    map_label = {j:i for i,j in enumerate(list_label)}\n",
    "    X_train[col] = X_train[col].map(map_label)\n",
    "    \n",
    "    dict_cat[col] = {}\n",
    "    dict_cat[col]['fillna'] = value_fillna\n",
    "    dict_cat[col]['map_label'] = map_label\n",
    "    dict_cat[col]['num_label'] = len(list_label)\n",
    "\n",
    "print('Done')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "23602c9c-e7c4-44a3-b4de-3afb2321e187",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>Age</th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Pregnancies_bin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.313823</td>\n",
       "      <td>0.708574</td>\n",
       "      <td>0.496403</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.027125</td>\n",
       "      <td>0.702316</td>\n",
       "      <td>0.223022</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.173992</td>\n",
       "      <td>0.557487</td>\n",
       "      <td>0.410072</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.166544</td>\n",
       "      <td>0.419302</td>\n",
       "      <td>0.640288</td>\n",
       "      <td>0.369565</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.303618</td>\n",
       "      <td>0.712381</td>\n",
       "      <td>0.474820</td>\n",
       "      <td>0.152174</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>0.013546</td>\n",
       "      <td>0.693011</td>\n",
       "      <td>0.669065</td>\n",
       "      <td>0.108696</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>0.168592</td>\n",
       "      <td>0.676110</td>\n",
       "      <td>0.690647</td>\n",
       "      <td>0.152174</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>0.270176</td>\n",
       "      <td>0.962270</td>\n",
       "      <td>0.352518</td>\n",
       "      <td>0.173913</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>0.079172</td>\n",
       "      <td>0.712423</td>\n",
       "      <td>0.316547</td>\n",
       "      <td>0.108696</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>0.051404</td>\n",
       "      <td>0.953895</td>\n",
       "      <td>0.374101</td>\n",
       "      <td>0.043478</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      DiabetesPedigreeFunction       BMI   Glucose       Age  Pregnancies  \\\n",
       "0                     0.313823  0.708574  0.496403  0.000000     0.000000   \n",
       "1                     0.027125  0.702316  0.223022  0.021739     0.230769   \n",
       "2                     0.173992  0.557487  0.410072  0.000000     0.230769   \n",
       "3                     0.166544  0.419302  0.640288  0.369565     0.076923   \n",
       "4                     0.303618  0.712381  0.474820  0.152174     0.076923   \n",
       "...                        ...       ...       ...       ...          ...   \n",
       "1995                  0.013546  0.693011  0.669065  0.108696     0.307692   \n",
       "1996                  0.168592  0.676110  0.690647  0.152174     0.461538   \n",
       "1997                  0.270176  0.962270  0.352518  0.173913     0.538462   \n",
       "1998                  0.079172  0.712423  0.316547  0.108696     0.153846   \n",
       "1999                  0.051404  0.953895  0.374101  0.043478     0.384615   \n",
       "\n",
       "      Pregnancies_bin  \n",
       "0                   2  \n",
       "1                   1  \n",
       "2                   1  \n",
       "3                   0  \n",
       "4                   0  \n",
       "...               ...  \n",
       "1995                1  \n",
       "1996                3  \n",
       "1997                3  \n",
       "1998                0  \n",
       "1999                1  \n",
       "\n",
       "[2000 rows x 6 columns]"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "f14500b9-d05d-4c8d-b230-7e4cbbbec1e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3000 entries, 0 to 2999\n",
      "Data columns (total 6 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   DiabetesPedigreeFunction  3000 non-null   float64\n",
      " 1   BMI                       3000 non-null   float64\n",
      " 2   Glucose                   3000 non-null   float64\n",
      " 3   Age                       3000 non-null   float64\n",
      " 4   Pregnancies               3000 non-null   float64\n",
      " 5   Pregnancies_bin           3000 non-null   int64  \n",
      "dtypes: float64(5), int64(1)\n",
      "memory usage: 140.8 KB\n"
     ]
    }
   ],
   "source": [
    "X_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3312c29-240f-4ed4-84d7-5958b5b6930c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "ca62731b-a52e-43b2-829b-90f96639dd98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'-1': 0, '-3': 1, '0': 2, '3-': 3, 'unknown': 4}"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "ohe = OneHotEncoder()\n",
    "ohe.fit(X_train['Pregnancies_bin'].values.reshape(-1, 1))\n",
    "list_ohe_label = sorted(list(set(le.classes_) | set(['unknown'])))\n",
    "map_ohe_label = {j:i for i,j in enumerate(list_label)}\n",
    "\n",
    "map_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de7d3d5-3774-4e23-b925-84b1d1ba0343",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "31ee77a7-d232-4fe8-a092-3cebbd5efe2f",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "source": [
    "cat_cols = ['facility_id', 'icu_id']\n",
    "train_x=n_train\n",
    "train_y=y_train\n",
    "test_x=n_test\n",
    "\n",
    "cv = list(StratifiedKFold(n_splits=N_FOLDS, shuffle=True, random_state=71).split(n_train, y_train ))\n",
    "for  nfold in list_nfold :\n",
    "    tr_idx, va_idx_ = cv[nfold][0], cv[nfold][1]\n",
    "    # 学習データからバリデーションデータを分ける\n",
    "    tr_x, va_x = train_x.iloc[tr_idx].copy(), train_x.iloc[va_idx].copy()\n",
    "    tr_y, va_y = train_y.iloc[tr_idx], train_y.iloc[va_idx]\n",
    "    # 変数をループしてtarget encoding\n",
    "    for c in cat_cols:\n",
    "        # 学習データ全体で各カテゴリにおけるtargetの平均を計算\n",
    "        data_tmp = pd.DataFrame({c: tr_x[c], 'target': tr_y['target_label']})\n",
    "        target_mean = data_tmp.groupby(c)['target'].mean()\n",
    "        # バリデーションデータのカテゴリを置換\n",
    "        va_x.loc[:, c] = va_x[c].map(target_mean)\n",
    "\n",
    "        # 学習データの変換後の値を格納する配列を準備\n",
    "        tmp = np.repeat(np.nan, tr_x.shape[0])\n",
    "        \n",
    "        cv_encoding = list(StratifiedKFold(n_splits=5, shuffle=True, random_state=71).split(tr_x,tr_y))\n",
    "        for  nfold in list_nfold:\n",
    "            idx_1, idx_2 = cv_encoding[nfold][0], cv_encoding[nfold][1]\n",
    "            # out-of-foldで各カテゴリにおける目的変数の平均を計算\n",
    "            target_mean = data_tmp.iloc[idx_1].groupby(c)['target'].mean()\n",
    "            # 変換後の値を一時配列に格納\n",
    "            tmp[idx_2] = tr_x[c].iloc[idx_2].map(target_mean)\n",
    "        \n",
    "        tr_x.loc[:, c] = tmp\n",
    "        print(tr_x)\n",
    "    # print(tr_x)\n",
    "    # ここでモデル学習\n",
    "# 必要に応じてencodeされた特徴量を保存し、あとで読み込めるようにしておく"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
